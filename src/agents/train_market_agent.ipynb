{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hBqi3PSSkXaF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import joblib\n",
        "from pandas import DataFrame as df\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load combined CSV (created in 2.1) ---\n",
        "data_path = \"/content/historical_prices_combined.csv\"\n",
        "df = pd.read_csv(data_path, index_col=[0,1])  # only works if CSV exists\n"
      ],
      "metadata": {
        "id": "RtXH_WyBkbx2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Strip spaces and standardize column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Check columns\n",
        "print(\"Columns in CSV:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3reFQAZSkj0Q",
        "outputId": "ec90c840-4c2c-47a2-ae84-293efef15596"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in CSV: ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock_Splits', 'Symbol', 'Capital_Gains']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Features for LSTM\n",
        "features = ['High', 'Low', 'Close', 'Volume']  # core numeric features\n",
        "processed_data = {}"
      ],
      "metadata": {
        "id": "4phodJktlaWn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker, data_dict in processed_data.items():\n",
        "    train_data = data_dict['train']\n",
        "    val_data = data_dict['val']\n",
        "    scaler = data_dict['scaler']  # get scaler\n",
        "\n",
        "    def create_sequences(data, seq_length=60):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_length, len(data)):\n",
        "            X.append(data[i-seq_length:i])\n",
        "            y.append(data[i, 2])  # predict 'Close'\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X_train, y_train = create_sequences(train_data)\n",
        "    X_val, y_val = create_sequences(val_data)\n",
        "\n",
        "    sequence_data[ticker] = {\n",
        "        'X_train': X_train,\n",
        "        'y_train': y_train,\n",
        "        'X_val': X_val,\n",
        "        'y_val': y_val,\n",
        "        'scaler': scaler  # add this here\n",
        "    }\n",
        "\n",
        "    print(f\"{ticker} sequences created: X_train {X_train.shape}, X_val {X_val.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1gTbAnrmVbL",
        "outputId": "f5e86576-7368-4dcb-d5ad-19e953a4ff78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "MSFT sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "GOOGL sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "AMZN sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "TSLA sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "META sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "NVDA sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "JPM sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "V sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "JNJ sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "SPY sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "QQQ sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "VTI sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "VOO sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "IWM sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "DIA sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "GLD sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "TLT sequences created: X_train (944, 60, 4), X_val (192, 60, 4)\n",
            "BTC-USD sequences created: X_train (1401, 60, 4), X_val (306, 60, 4)\n",
            "ETH-USD sequences created: X_train (1401, 60, 4), X_val (306, 60, 4)\n",
            "BNB-USD sequences created: X_train (1401, 60, 4), X_val (306, 60, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "sequence_length = 60  # use last 60 days to predict next day\n",
        "\n",
        "# Dictionary to store sequences per ticker\n",
        "sequence_data = {}"
      ],
      "metadata": {
        "id": "DRBwKyf7mZ1D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for ticker, data_dict in processed_data.items():\n",
        "    train_data = data_dict['train']\n",
        "    val_data = data_dict['val']\n",
        "\n",
        "    def create_sequences(data, seq_length=sequence_length):\n",
        "        X, y = [], []\n",
        "        for i in range(seq_length, len(data)):\n",
        "            X.append(data[i-seq_length:i])  # last seq_length days\n",
        "            y.append(data[i, 2])  # predict 'Close' price (index 2 in ['High','Low','Close','Volume'])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X_train, y_train = create_sequences(train_data)\n",
        "    X_val, y_val = create_sequences(val_data)\n",
        "\n",
        "    sequence_data[ticker] = {\n",
        "        'X_train': X_train,\n",
        "        'y_train': y_train,\n",
        "        'X_val': X_val,\n",
        "        'y_val': y_val\n",
        "    }\n",
        "\n",
        "    print(f\"{ticker} sequences created:\")\n",
        "    print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "    print(f\"  X_val: {X_val.shape}, y_val: {y_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0l8ETthm0um",
        "outputId": "13abc24d-02a4-4b4d-fd6a-79bc2b576add"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "MSFT sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "GOOGL sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "AMZN sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "TSLA sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "META sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "NVDA sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "JPM sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "V sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "JNJ sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "SPY sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "QQQ sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "VTI sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "VOO sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "IWM sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "DIA sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "GLD sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "TLT sequences created:\n",
            "  X_train: (944, 60, 4), y_train: (944,)\n",
            "  X_val: (192, 60, 4), y_val: (192,)\n",
            "BTC-USD sequences created:\n",
            "  X_train: (1401, 60, 4), y_train: (1401,)\n",
            "  X_val: (306, 60, 4), y_val: (306,)\n",
            "ETH-USD sequences created:\n",
            "  X_train: (1401, 60, 4), y_train: (1401,)\n",
            "  X_val: (306, 60, 4), y_val: (306,)\n",
            "BNB-USD sequences created:\n",
            "  X_train: (1401, 60, 4), y_train: (1401,)\n",
            "  X_val: (306, 60, 4), y_val: (306,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_features = 4  # ['High','Low','Close','Volume']\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "# Directory to save trained models\n",
        "os.makedirs(\"models/lstm\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "IEz04pCbm310"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker, seq_data in sequence_data.items():\n",
        "    X_train, y_train = seq_data['X_train'], seq_data['y_train']\n",
        "    X_val, y_val = seq_data['X_val'], seq_data['y_val']\n",
        "\n",
        "    # Build LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dense(1))  # predict next-day Close price\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=50,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Save model reference in sequence_data\n",
        "    sequence_data[ticker]['model'] = model\n",
        "    sequence_data[ticker]['history'] = history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt0XD4OGnTZ0",
        "outputId": "d8cd9cb8-11b3-4592-ea0b-a0f4b1d57846"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0356 - mae: 0.1396 - val_loss: 0.0138 - val_mae: 0.1041\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0035 - val_mae: 0.0462\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.7921e-04 - mae: 0.0252 - val_loss: 0.0028 - val_mae: 0.0396\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.2608e-04 - mae: 0.0243 - val_loss: 0.0029 - val_mae: 0.0408\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.2024e-04 - mae: 0.0240 - val_loss: 0.0025 - val_mae: 0.0366\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.1007e-04 - mae: 0.0241 - val_loss: 0.0025 - val_mae: 0.0371\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.3672e-04 - mae: 0.0231 - val_loss: 0.0024 - val_mae: 0.0364\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1574e-04 - mae: 0.0226 - val_loss: 0.0023 - val_mae: 0.0351\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3306e-04 - mae: 0.0226 - val_loss: 0.0028 - val_mae: 0.0414\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.7863e-04 - mae: 0.0220 - val_loss: 0.0028 - val_mae: 0.0412\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.2003e-04 - mae: 0.0209 - val_loss: 0.0022 - val_mae: 0.0351\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.6834e-04 - mae: 0.0218 - val_loss: 0.0024 - val_mae: 0.0372\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.2412e-04 - mae: 0.0213 - val_loss: 0.0021 - val_mae: 0.0346\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.9286e-04 - mae: 0.0207 - val_loss: 0.0019 - val_mae: 0.0314\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.5271e-04 - mae: 0.0198 - val_loss: 0.0021 - val_mae: 0.0326\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.5539e-04 - mae: 0.0201 - val_loss: 0.0020 - val_mae: 0.0326\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.1352e-04 - mae: 0.0195 - val_loss: 0.0019 - val_mae: 0.0322\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.0857e-04 - mae: 0.0191 - val_loss: 0.0019 - val_mae: 0.0317\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.4866e-04 - mae: 0.0199 - val_loss: 0.0019 - val_mae: 0.0311\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.1798e-04 - mae: 0.0194 - val_loss: 0.0018 - val_mae: 0.0307\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.6302e-04 - mae: 0.0187 - val_loss: 0.0019 - val_mae: 0.0322\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2454e-04 - mae: 0.0180 - val_loss: 0.0017 - val_mae: 0.0298\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4703e-04 - mae: 0.0182 - val_loss: 0.0018 - val_mae: 0.0308\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.4640e-04 - mae: 0.0181 - val_loss: 0.0016 - val_mae: 0.0283\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 5.9176e-04 - mae: 0.0192 - val_loss: 0.0016 - val_mae: 0.0280\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.0883e-04 - mae: 0.0176 - val_loss: 0.0016 - val_mae: 0.0283\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.4939e-04 - mae: 0.0181 - val_loss: 0.0020 - val_mae: 0.0339\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.8339e-04 - mae: 0.0184 - val_loss: 0.0017 - val_mae: 0.0297\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.2801e-04 - mae: 0.0177 - val_loss: 0.0020 - val_mae: 0.0344\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.6286e-04 - mae: 0.0186 - val_loss: 0.0015 - val_mae: 0.0269\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.7135e-04 - mae: 0.0172 - val_loss: 0.0015 - val_mae: 0.0269\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.6519e-04 - mae: 0.0170 - val_loss: 0.0015 - val_mae: 0.0267\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4855e-04 - mae: 0.0167 - val_loss: 0.0015 - val_mae: 0.0268\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9066e-04 - mae: 0.0172 - val_loss: 0.0016 - val_mae: 0.0292\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.1491e-04 - mae: 0.0175 - val_loss: 0.0014 - val_mae: 0.0261\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.6369e-04 - mae: 0.0166 - val_loss: 0.0014 - val_mae: 0.0259\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.1898e-04 - mae: 0.0160 - val_loss: 0.0013 - val_mae: 0.0254\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.3172e-04 - mae: 0.0162 - val_loss: 0.0014 - val_mae: 0.0258\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1306e-04 - mae: 0.0159 - val_loss: 0.0014 - val_mae: 0.0265\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.2884e-04 - mae: 0.0158 - val_loss: 0.0013 - val_mae: 0.0249\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9905e-04 - mae: 0.0173 - val_loss: 0.0013 - val_mae: 0.0248\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.3343e-04 - mae: 0.0159 - val_loss: 0.0013 - val_mae: 0.0249\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.3120e-04 - mae: 0.0160 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 4.4026e-04 - mae: 0.0159 - val_loss: 0.0013 - val_mae: 0.0256\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.2466e-04 - mae: 0.0161 - val_loss: 0.0012 - val_mae: 0.0241\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0435e-04 - mae: 0.0157 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.5045e-04 - mae: 0.0167 - val_loss: 0.0015 - val_mae: 0.0299\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.8955e-04 - mae: 0.0153 - val_loss: 0.0012 - val_mae: 0.0235\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.6923e-04 - mae: 0.0148 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.2885e-04 - mae: 0.0160 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0658 - mae: 0.1872 - val_loss: 0.0321 - val_mae: 0.1663\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0016 - val_mae: 0.0308\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.9905e-04 - mae: 0.0241 - val_loss: 0.0019 - val_mae: 0.0360\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.7418e-04 - mae: 0.0225 - val_loss: 0.0020 - val_mae: 0.0363\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.8042e-04 - mae: 0.0227 - val_loss: 0.0023 - val_mae: 0.0402\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.6748e-04 - mae: 0.0224 - val_loss: 0.0017 - val_mae: 0.0343\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.2533e-04 - mae: 0.0217 - val_loss: 0.0016 - val_mae: 0.0320\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.8984e-04 - mae: 0.0213 - val_loss: 0.0015 - val_mae: 0.0312\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.3863e-04 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 6.2820e-04 - mae: 0.0201 - val_loss: 0.0014 - val_mae: 0.0299\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.2912e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0327\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.6147e-04 - mae: 0.0208 - val_loss: 0.0015 - val_mae: 0.0311\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.2087e-04 - mae: 0.0203 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.6846e-04 - mae: 0.0191 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.8795e-04 - mae: 0.0197 - val_loss: 0.0019 - val_mae: 0.0363\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3393e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0254\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.6100e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.2991e-04 - mae: 0.0184 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.4204e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.4631e-04 - mae: 0.0189 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7032e-04 - mae: 0.0174 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1629e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mae: 0.0241\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.0360e-04 - mae: 0.0178 - val_loss: 8.7686e-04 - val_mae: 0.0221\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.0534e-04 - mae: 0.0175 - val_loss: 8.6723e-04 - val_mae: 0.0220\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2543e-04 - mae: 0.0184 - val_loss: 8.1596e-04 - val_mae: 0.0210\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.6312e-04 - mae: 0.0173 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4921e-04 - mae: 0.0169 - val_loss: 7.8692e-04 - val_mae: 0.0204\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.6201e-04 - mae: 0.0170 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.1849e-04 - mae: 0.0159 - val_loss: 7.8821e-04 - val_mae: 0.0205\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.4103e-04 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.0604e-04 - mae: 0.0178 - val_loss: 9.1966e-04 - val_mae: 0.0229\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4177e-04 - mae: 0.0164 - val_loss: 7.8833e-04 - val_mae: 0.0206\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.6505e-04 - mae: 0.0169 - val_loss: 8.8120e-04 - val_mae: 0.0223\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.9590e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.8646e-04 - mae: 0.0155 - val_loss: 6.9508e-04 - val_mae: 0.0189\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.3938e-04 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.0514e-04 - mae: 0.0159 - val_loss: 8.1006e-04 - val_mae: 0.0211\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.1387e-04 - mae: 0.0160 - val_loss: 8.1787e-04 - val_mae: 0.0221\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.4047e-04 - mae: 0.0167 - val_loss: 9.6571e-04 - val_mae: 0.0240\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.6469e-04 - mae: 0.0151 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7358e-04 - mae: 0.0153 - val_loss: 7.0621e-04 - val_mae: 0.0191\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0618e-04 - mae: 0.0157 - val_loss: 6.7439e-04 - val_mae: 0.0186\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4988e-04 - mae: 0.0147 - val_loss: 7.9118e-04 - val_mae: 0.0211\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.4316e-04 - mae: 0.0146 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.5054e-04 - mae: 0.0146 - val_loss: 6.5270e-04 - val_mae: 0.0183\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7846e-04 - mae: 0.0155 - val_loss: 7.5882e-04 - val_mae: 0.0206\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.5942e-04 - mae: 0.0147 - val_loss: 8.4886e-04 - val_mae: 0.0224\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 3.6331e-04 - mae: 0.0149 - val_loss: 7.6238e-04 - val_mae: 0.0208\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.1516e-04 - mae: 0.0140 - val_loss: 7.4415e-04 - val_mae: 0.0206\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4228e-04 - mae: 0.0147 - val_loss: 7.1086e-04 - val_mae: 0.0199\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0134 - mae: 0.0831 - val_loss: 0.0056 - val_mae: 0.0580\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.7758e-04 - mae: 0.0189 - val_loss: 0.0018 - val_mae: 0.0331\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.3404e-04 - mae: 0.0163 - val_loss: 0.0017 - val_mae: 0.0323\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.9583e-04 - mae: 0.0158 - val_loss: 0.0017 - val_mae: 0.0319\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7572e-04 - mae: 0.0151 - val_loss: 0.0014 - val_mae: 0.0296\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0519e-04 - mae: 0.0158 - val_loss: 0.0015 - val_mae: 0.0304\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.7880e-04 - mae: 0.0152 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5515e-04 - mae: 0.0147 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.5620e-04 - mae: 0.0149 - val_loss: 9.9157e-04 - val_mae: 0.0246\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2423e-04 - mae: 0.0139 - val_loss: 9.5449e-04 - val_mae: 0.0242\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0574e-04 - mae: 0.0135 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.1265e-04 - mae: 0.0138 - val_loss: 8.5050e-04 - val_mae: 0.0228\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.4022e-04 - mae: 0.0142 - val_loss: 8.1413e-04 - val_mae: 0.0222\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.7323e-04 - mae: 0.0128 - val_loss: 7.8874e-04 - val_mae: 0.0217\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9415e-04 - mae: 0.0131 - val_loss: 7.7377e-04 - val_mae: 0.0215\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1512e-04 - mae: 0.0140 - val_loss: 8.7124e-04 - val_mae: 0.0230\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.8602e-04 - mae: 0.0128 - val_loss: 7.0282e-04 - val_mae: 0.0204\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.8364e-04 - mae: 0.0131 - val_loss: 9.9421e-04 - val_mae: 0.0248\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9909e-04 - mae: 0.0131 - val_loss: 7.0802e-04 - val_mae: 0.0204\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0110e-04 - mae: 0.0131 - val_loss: 6.7851e-04 - val_mae: 0.0201\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5139e-04 - mae: 0.0125 - val_loss: 7.3261e-04 - val_mae: 0.0211\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.8541e-04 - mae: 0.0132 - val_loss: 6.8119e-04 - val_mae: 0.0201\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.1052e-04 - mae: 0.0112 - val_loss: 7.8142e-04 - val_mae: 0.0219\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.6809e-04 - mae: 0.0126 - val_loss: 6.1353e-04 - val_mae: 0.0191\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.4231e-04 - mae: 0.0119 - val_loss: 6.7360e-04 - val_mae: 0.0203\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.7610e-04 - mae: 0.0124 - val_loss: 6.0292e-04 - val_mae: 0.0188\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.3468e-04 - mae: 0.0117 - val_loss: 8.2274e-04 - val_mae: 0.0226\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5324e-04 - mae: 0.0124 - val_loss: 6.7264e-04 - val_mae: 0.0201\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.4103e-04 - mae: 0.0116 - val_loss: 5.9008e-04 - val_mae: 0.0188\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.9734e-04 - mae: 0.0109 - val_loss: 7.6853e-04 - val_mae: 0.0218\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.3216e-04 - mae: 0.0119 - val_loss: 5.6843e-04 - val_mae: 0.0183\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3456e-04 - mae: 0.0119 - val_loss: 6.0710e-04 - val_mae: 0.0190\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2774e-04 - mae: 0.0116 - val_loss: 6.4591e-04 - val_mae: 0.0198\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.1727e-04 - mae: 0.0113 - val_loss: 5.6749e-04 - val_mae: 0.0185\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1499e-04 - mae: 0.0113 - val_loss: 5.3868e-04 - val_mae: 0.0178\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.2074e-04 - mae: 0.0115 - val_loss: 5.4058e-04 - val_mae: 0.0180\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2017e-04 - mae: 0.0114 - val_loss: 5.5450e-04 - val_mae: 0.0180\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.3414e-04 - mae: 0.0115 - val_loss: 5.4589e-04 - val_mae: 0.0179\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.1858e-04 - mae: 0.0117 - val_loss: 5.6554e-04 - val_mae: 0.0181\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.9924e-04 - mae: 0.0111 - val_loss: 5.5176e-04 - val_mae: 0.0179\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.9180e-04 - mae: 0.0107 - val_loss: 5.6767e-04 - val_mae: 0.0183\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.0291e-04 - mae: 0.0111 - val_loss: 5.1487e-04 - val_mae: 0.0169\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2298e-04 - mae: 0.0115 - val_loss: 5.5213e-04 - val_mae: 0.0181\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0457e-04 - mae: 0.0107 - val_loss: 5.6158e-04 - val_mae: 0.0183\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.9826e-04 - mae: 0.0109 - val_loss: 5.8685e-04 - val_mae: 0.0188\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.3838e-04 - mae: 0.0121 - val_loss: 5.2464e-04 - val_mae: 0.0174\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.0920e-04 - mae: 0.0112 - val_loss: 4.8087e-04 - val_mae: 0.0164\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.9818e-04 - mae: 0.0107 - val_loss: 4.9308e-04 - val_mae: 0.0168\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.9958e-04 - mae: 0.0107 - val_loss: 6.4486e-04 - val_mae: 0.0197\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.9811e-04 - mae: 0.0108 - val_loss: 4.7915e-04 - val_mae: 0.0165\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1180 - mae: 0.2640 - val_loss: 0.0385 - val_mae: 0.1861\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0558 - val_loss: 0.0090 - val_mae: 0.0832\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0318 - val_loss: 0.0037 - val_mae: 0.0500\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0029 - val_mae: 0.0432\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0029 - val_mae: 0.0431\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0025 - val_mae: 0.0386\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0024 - val_mae: 0.0380\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0026 - val_mae: 0.0409\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 0.0021 - val_mae: 0.0350\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0248 - val_loss: 0.0019 - val_mae: 0.0332\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0022 - val_mae: 0.0366\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9865e-04 - mae: 0.0237 - val_loss: 0.0026 - val_mae: 0.0412\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.3620e-04 - mae: 0.0236 - val_loss: 0.0020 - val_mae: 0.0344\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.0944e-04 - mae: 0.0231 - val_loss: 0.0021 - val_mae: 0.0360\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.4422e-04 - mae: 0.0221 - val_loss: 0.0017 - val_mae: 0.0315\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.6410e-04 - mae: 0.0225 - val_loss: 0.0015 - val_mae: 0.0289\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3179e-04 - mae: 0.0220 - val_loss: 0.0015 - val_mae: 0.0281\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.1821e-04 - mae: 0.0218 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1023e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.4467e-04 - mae: 0.0209 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.0242e-04 - mae: 0.0214 - val_loss: 0.0015 - val_mae: 0.0293\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.1920e-04 - mae: 0.0218 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.0484e-04 - mae: 0.0206 - val_loss: 0.0020 - val_mae: 0.0363\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.7553e-04 - mae: 0.0215 - val_loss: 0.0016 - val_mae: 0.0308\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.6945e-04 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.3271e-04 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.4457e-04 - mae: 0.0208 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.1106e-04 - mae: 0.0203 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.8650e-04 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.2694e-04 - mae: 0.0193 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.8306e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0304\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.7031e-04 - mae: 0.0195 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.0082e-04 - mae: 0.0197 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 6.2905e-04 - mae: 0.0193 - val_loss: 0.0011 - val_mae: 0.0253\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.8579e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.9642e-04 - mae: 0.0204 - val_loss: 0.0011 - val_mae: 0.0249\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.7318e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0302\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.8379e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.9469e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.7727e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mae: 0.0241\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.8306e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0306\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.2730e-04 - mae: 0.0193 - val_loss: 0.0011 - val_mae: 0.0254\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.6050e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.8535e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mae: 0.0242\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.6528e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0249\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.1666e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.7493e-04 - mae: 0.0177 - val_loss: 0.0015 - val_mae: 0.0306\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4517e-04 - mae: 0.0181 - val_loss: 9.8803e-04 - val_mae: 0.0233\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3405e-04 - mae: 0.0174 - val_loss: 0.0013 - val_mae: 0.0278\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3450e-04 - mae: 0.0178 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0190 - mae: 0.1047 - val_loss: 0.0048 - val_mae: 0.0544\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0043 - val_mae: 0.0521\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0034 - val_mae: 0.0440\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0402\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0026 - val_mae: 0.0394\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0372\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0027 - val_mae: 0.0408\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0023 - val_mae: 0.0364\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0021 - val_mae: 0.0352\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 0.0026 - val_mae: 0.0404\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0020 - val_mae: 0.0342\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0022 - val_mae: 0.0368\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0021 - val_mae: 0.0355\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.0491e-04 - mae: 0.0227 - val_loss: 0.0019 - val_mae: 0.0341\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9446e-04 - mae: 0.0236 - val_loss: 0.0018 - val_mae: 0.0327\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.9027e-04 - mae: 0.0219 - val_loss: 0.0020 - val_mae: 0.0347\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.4479e-04 - mae: 0.0226 - val_loss: 0.0020 - val_mae: 0.0354\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 8.7331e-04 - mae: 0.0217 - val_loss: 0.0017 - val_mae: 0.0322\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.3668e-04 - mae: 0.0217 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6402e-04 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0311\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.5391e-04 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0309\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.9970e-04 - mae: 0.0212 - val_loss: 0.0016 - val_mae: 0.0305\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.2462e-04 - mae: 0.0227 - val_loss: 0.0019 - val_mae: 0.0346\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.9994e-04 - mae: 0.0213 - val_loss: 0.0021 - val_mae: 0.0359\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.0696e-04 - mae: 0.0224 - val_loss: 0.0019 - val_mae: 0.0344\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.6421e-04 - mae: 0.0219 - val_loss: 0.0015 - val_mae: 0.0303\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.1732e-04 - mae: 0.0212 - val_loss: 0.0015 - val_mae: 0.0299\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.5993e-04 - mae: 0.0206 - val_loss: 0.0015 - val_mae: 0.0293\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.4608e-04 - mae: 0.0212 - val_loss: 0.0016 - val_mae: 0.0316\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.6985e-04 - mae: 0.0204 - val_loss: 0.0017 - val_mae: 0.0322\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.8933e-04 - mae: 0.0226 - val_loss: 0.0016 - val_mae: 0.0310\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.8229e-04 - mae: 0.0191 - val_loss: 0.0014 - val_mae: 0.0290\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.4115e-04 - mae: 0.0201 - val_loss: 0.0017 - val_mae: 0.0321\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.6179e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.8058e-04 - mae: 0.0192 - val_loss: 0.0016 - val_mae: 0.0312\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9118e-04 - mae: 0.0192 - val_loss: 0.0014 - val_mae: 0.0286\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.9812e-04 - mae: 0.0193 - val_loss: 0.0016 - val_mae: 0.0307\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.1536e-04 - mae: 0.0196 - val_loss: 0.0015 - val_mae: 0.0305\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.4129e-04 - mae: 0.0217 - val_loss: 0.0013 - val_mae: 0.0280\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.9312e-04 - mae: 0.0197 - val_loss: 0.0013 - val_mae: 0.0278\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.6818e-04 - mae: 0.0187 - val_loss: 0.0013 - val_mae: 0.0278\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.4441e-04 - mae: 0.0187 - val_loss: 0.0015 - val_mae: 0.0300\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.9559e-04 - mae: 0.0198 - val_loss: 0.0013 - val_mae: 0.0278\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.9900e-04 - mae: 0.0184 - val_loss: 0.0015 - val_mae: 0.0298\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.9743e-04 - mae: 0.0194 - val_loss: 0.0018 - val_mae: 0.0334\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.7672e-04 - mae: 0.0192 - val_loss: 0.0014 - val_mae: 0.0290\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.5073e-04 - mae: 0.0183 - val_loss: 0.0013 - val_mae: 0.0276\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.2004e-04 - mae: 0.0184 - val_loss: 0.0015 - val_mae: 0.0304\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.6893e-04 - mae: 0.0188 - val_loss: 0.0014 - val_mae: 0.0286\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.1462e-04 - mae: 0.0178 - val_loss: 0.0013 - val_mae: 0.0280\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0650 - mae: 0.1919 - val_loss: 0.0393 - val_mae: 0.1897\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0116 - val_mae: 0.0971\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 7.3408e-04 - mae: 0.0200 - val_loss: 0.0038 - val_mae: 0.0535\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 6.1416e-04 - mae: 0.0184 - val_loss: 0.0031 - val_mae: 0.0470\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.4713e-04 - mae: 0.0189 - val_loss: 0.0027 - val_mae: 0.0438\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7582e-04 - mae: 0.0182 - val_loss: 0.0030 - val_mae: 0.0466\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.1531e-04 - mae: 0.0169 - val_loss: 0.0023 - val_mae: 0.0387\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.3379e-04 - mae: 0.0171 - val_loss: 0.0022 - val_mae: 0.0373\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.8232e-04 - mae: 0.0161 - val_loss: 0.0023 - val_mae: 0.0387\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.6063e-04 - mae: 0.0160 - val_loss: 0.0021 - val_mae: 0.0373\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.9466e-04 - mae: 0.0164 - val_loss: 0.0021 - val_mae: 0.0370\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.3132e-04 - mae: 0.0157 - val_loss: 0.0021 - val_mae: 0.0360\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.1326e-04 - mae: 0.0154 - val_loss: 0.0022 - val_mae: 0.0379\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.0076e-04 - mae: 0.0164 - val_loss: 0.0020 - val_mae: 0.0352\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.8997e-04 - mae: 0.0148 - val_loss: 0.0020 - val_mae: 0.0351\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.3632e-04 - mae: 0.0153 - val_loss: 0.0019 - val_mae: 0.0352\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.8184e-04 - mae: 0.0145 - val_loss: 0.0018 - val_mae: 0.0338\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1404e-04 - mae: 0.0150 - val_loss: 0.0018 - val_mae: 0.0335\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7886e-04 - mae: 0.0142 - val_loss: 0.0018 - val_mae: 0.0332\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.6237e-04 - mae: 0.0145 - val_loss: 0.0018 - val_mae: 0.0337\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.7638e-04 - mae: 0.0146 - val_loss: 0.0017 - val_mae: 0.0327\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.2235e-04 - mae: 0.0135 - val_loss: 0.0016 - val_mae: 0.0312\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0447e-04 - mae: 0.0144 - val_loss: 0.0015 - val_mae: 0.0306\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4341e-04 - mae: 0.0139 - val_loss: 0.0015 - val_mae: 0.0302\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7610e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0318\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2567e-04 - mae: 0.0136 - val_loss: 0.0014 - val_mae: 0.0295\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.3747e-04 - mae: 0.0135 - val_loss: 0.0018 - val_mae: 0.0347\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4402e-04 - mae: 0.0138 - val_loss: 0.0013 - val_mae: 0.0281\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0503e-04 - mae: 0.0133 - val_loss: 0.0014 - val_mae: 0.0293\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.1634e-04 - mae: 0.0131 - val_loss: 0.0016 - val_mae: 0.0327\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3053e-04 - mae: 0.0133 - val_loss: 0.0012 - val_mae: 0.0268\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.3331e-04 - mae: 0.0130 - val_loss: 0.0012 - val_mae: 0.0262\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.1418e-04 - mae: 0.0131 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5904e-04 - mae: 0.0121 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.9607e-04 - mae: 0.0124 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.7610e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.7792e-04 - mae: 0.0121 - val_loss: 0.0012 - val_mae: 0.0266\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 2.7362e-04 - mae: 0.0126 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.9727e-04 - mae: 0.0127 - val_loss: 0.0010 - val_mae: 0.0239\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2090e-04 - mae: 0.0129 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2530e-04 - mae: 0.0131 - val_loss: 9.7312e-04 - val_mae: 0.0235\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.7231e-04 - mae: 0.0122 - val_loss: 0.0012 - val_mae: 0.0269\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.9731e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5842e-04 - mae: 0.0118 - val_loss: 9.8057e-04 - val_mae: 0.0241\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0059e-04 - mae: 0.0123 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.5366e-04 - mae: 0.0119 - val_loss: 9.6951e-04 - val_mae: 0.0240\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.3328e-04 - mae: 0.0113 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.0777e-04 - mae: 0.0124 - val_loss: 9.2831e-04 - val_mae: 0.0226\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.6755e-04 - mae: 0.0120 - val_loss: 8.5387e-04 - val_mae: 0.0218\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.4656e-04 - mae: 0.0115 - val_loss: 8.9991e-04 - val_mae: 0.0229\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0647\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7030e-04 - mae: 0.0157 - val_loss: 0.0016 - val_mae: 0.0309\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.5341e-04 - mae: 0.0121 - val_loss: 0.0017 - val_mae: 0.0330\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 3.9268e-04 - mae: 0.0132 - val_loss: 0.0028 - val_mae: 0.0459\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 3.5485e-04 - mae: 0.0120 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2228e-04 - mae: 0.0130 - val_loss: 0.0014 - val_mae: 0.0273\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.0240e-04 - mae: 0.0112 - val_loss: 0.0015 - val_mae: 0.0310\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.9981e-04 - mae: 0.0109 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.9677e-04 - mae: 0.0110 - val_loss: 0.0020 - val_mae: 0.0385\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.7989e-04 - mae: 0.0109 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.4885e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.3852e-04 - mae: 0.0096 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.1399e-04 - mae: 0.0092 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.8715e-04 - mae: 0.0112 - val_loss: 0.0036 - val_mae: 0.0539\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.3791e-04 - mae: 0.0103 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.4952e-04 - mae: 0.0097 - val_loss: 0.0010 - val_mae: 0.0256\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.1957e-04 - mae: 0.0096 - val_loss: 9.3686e-04 - val_mae: 0.0236\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.0502e-04 - mae: 0.0090 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0404e-04 - mae: 0.0088 - val_loss: 9.2610e-04 - val_mae: 0.0239\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5216e-04 - mae: 0.0099 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.9849e-04 - mae: 0.0088 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.9463e-04 - mae: 0.0088 - val_loss: 8.5616e-04 - val_mae: 0.0215\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 2.0769e-04 - mae: 0.0096 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.9343e-04 - mae: 0.0085 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.7208e-04 - mae: 0.0084 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.4884e-04 - mae: 0.0076 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4870e-04 - mae: 0.0076 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1363e-04 - mae: 0.0090 - val_loss: 0.0014 - val_mae: 0.0314\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.8062e-04 - mae: 0.0088 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6533e-04 - mae: 0.0082 - val_loss: 7.7565e-04 - val_mae: 0.0214\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5270e-04 - mae: 0.0082 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.6213e-04 - mae: 0.0083 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6730e-04 - mae: 0.0083 - val_loss: 8.0658e-04 - val_mae: 0.0223\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.2116e-04 - mae: 0.0072 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4772e-04 - mae: 0.0077 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5679e-04 - mae: 0.0079 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.3317e-04 - mae: 0.0071 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5325e-04 - mae: 0.0077 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.5063e-04 - mae: 0.0076 - val_loss: 7.3612e-04 - val_mae: 0.0208\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4562e-04 - mae: 0.0077 - val_loss: 0.0021 - val_mae: 0.0394\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.6181e-04 - mae: 0.0080 - val_loss: 7.2913e-04 - val_mae: 0.0208\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.3050e-04 - mae: 0.0076 - val_loss: 8.0097e-04 - val_mae: 0.0221\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4026e-04 - mae: 0.0076 - val_loss: 9.4441e-04 - val_mae: 0.0244\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.4684e-04 - mae: 0.0082 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.2319e-04 - mae: 0.0075 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.3346e-04 - mae: 0.0074 - val_loss: 8.9342e-04 - val_mae: 0.0237\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.5658e-04 - mae: 0.0083 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.1265e-04 - mae: 0.0068 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.3405e-04 - mae: 0.0075 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.3606e-04 - mae: 0.0077 - val_loss: 9.0839e-04 - val_mae: 0.0242\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0173 - mae: 0.0942 - val_loss: 0.0084 - val_mae: 0.0867\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.0671e-04 - mae: 0.0189 - val_loss: 0.0030 - val_mae: 0.0437\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.6737e-04 - mae: 0.0151 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.2567e-04 - mae: 0.0144 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.2024e-04 - mae: 0.0139 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.1210e-04 - mae: 0.0139 - val_loss: 0.0011 - val_mae: 0.0245\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.9435e-04 - mae: 0.0132 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.8467e-04 - mae: 0.0131 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.0132e-04 - mae: 0.0136 - val_loss: 0.0017 - val_mae: 0.0309\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.7047e-04 - mae: 0.0127 - val_loss: 9.7086e-04 - val_mae: 0.0232\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.6246e-04 - mae: 0.0125 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.8398e-04 - mae: 0.0129 - val_loss: 9.5253e-04 - val_mae: 0.0224\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.4491e-04 - mae: 0.0124 - val_loss: 9.0208e-04 - val_mae: 0.0220\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.3513e-04 - mae: 0.0116 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.6945e-04 - mae: 0.0125 - val_loss: 8.6062e-04 - val_mae: 0.0228\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.2567e-04 - mae: 0.0115 - val_loss: 8.4082e-04 - val_mae: 0.0225\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.4020e-04 - mae: 0.0120 - val_loss: 7.8994e-04 - val_mae: 0.0209\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3558e-04 - mae: 0.0116 - val_loss: 8.3033e-04 - val_mae: 0.0205\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2976e-04 - mae: 0.0117 - val_loss: 8.3085e-04 - val_mae: 0.0205\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.1462e-04 - mae: 0.0114 - val_loss: 0.0010 - val_mae: 0.0263\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.2619e-04 - mae: 0.0114 - val_loss: 7.6885e-04 - val_mae: 0.0217\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2519e-04 - mae: 0.0112 - val_loss: 7.1647e-04 - val_mae: 0.0202\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.2056e-04 - mae: 0.0114 - val_loss: 8.5836e-04 - val_mae: 0.0239\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.2339e-04 - mae: 0.0115 - val_loss: 8.6631e-04 - val_mae: 0.0241\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0188e-04 - mae: 0.0107 - val_loss: 0.0014 - val_mae: 0.0325\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.1085e-04 - mae: 0.0111 - val_loss: 8.6739e-04 - val_mae: 0.0242\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 2.0052e-04 - mae: 0.0108 - val_loss: 6.4530e-04 - val_mae: 0.0186\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.9048e-04 - mae: 0.0106 - val_loss: 8.5597e-04 - val_mae: 0.0241\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.9633e-04 - mae: 0.0108 - val_loss: 8.9313e-04 - val_mae: 0.0248\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.8272e-04 - mae: 0.0103 - val_loss: 6.2106e-04 - val_mae: 0.0183\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0217e-04 - mae: 0.0110 - val_loss: 0.0012 - val_mae: 0.0294\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.8014e-04 - mae: 0.0102 - val_loss: 8.8481e-04 - val_mae: 0.0249\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.8010e-04 - mae: 0.0103 - val_loss: 8.0254e-04 - val_mae: 0.0233\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.5690e-04 - mae: 0.0097 - val_loss: 8.8238e-04 - val_mae: 0.0249\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.8451e-04 - mae: 0.0103 - val_loss: 9.1830e-04 - val_mae: 0.0256\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.7658e-04 - mae: 0.0103 - val_loss: 6.1091e-04 - val_mae: 0.0172\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.7288e-04 - mae: 0.0100 - val_loss: 5.6353e-04 - val_mae: 0.0171\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.8854e-04 - mae: 0.0106 - val_loss: 6.8741e-04 - val_mae: 0.0211\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6283e-04 - mae: 0.0098 - val_loss: 5.6089e-04 - val_mae: 0.0167\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.6172e-04 - mae: 0.0098 - val_loss: 0.0010 - val_mae: 0.0279\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6076e-04 - mae: 0.0096 - val_loss: 6.2503e-04 - val_mae: 0.0197\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.6259e-04 - mae: 0.0098 - val_loss: 5.5602e-04 - val_mae: 0.0165\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.7149e-04 - mae: 0.0097 - val_loss: 8.4132e-04 - val_mae: 0.0243\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.5431e-04 - mae: 0.0094 - val_loss: 0.0021 - val_mae: 0.0411\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.8388e-04 - mae: 0.0104 - val_loss: 9.4928e-04 - val_mae: 0.0263\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.3281e-04 - mae: 0.0088 - val_loss: 5.9485e-04 - val_mae: 0.0171\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.5027e-04 - mae: 0.0094 - val_loss: 5.1261e-04 - val_mae: 0.0166\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.4286e-04 - mae: 0.0092 - val_loss: 5.2816e-04 - val_mae: 0.0175\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.3500e-04 - mae: 0.0089 - val_loss: 7.0438e-04 - val_mae: 0.0219\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.4953e-04 - mae: 0.0091 - val_loss: 5.1547e-04 - val_mae: 0.0172\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0576 - mae: 0.1812 - val_loss: 0.0701 - val_mae: 0.2603\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0075 - val_mae: 0.0781\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0024 - val_mae: 0.0364\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0020 - val_mae: 0.0354\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0010 - mae: 0.0254 - val_loss: 0.0020 - val_mae: 0.0355\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.5451e-04 - mae: 0.0243 - val_loss: 0.0024 - val_mae: 0.0361\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 9.6022e-04 - mae: 0.0242 - val_loss: 0.0024 - val_mae: 0.0359\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.8270e-04 - mae: 0.0232 - val_loss: 0.0025 - val_mae: 0.0362\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.1094e-04 - mae: 0.0231 - val_loss: 0.0022 - val_mae: 0.0342\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.5632e-04 - mae: 0.0213 - val_loss: 0.0024 - val_mae: 0.0357\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.5745e-04 - mae: 0.0224 - val_loss: 0.0022 - val_mae: 0.0340\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.0730e-04 - mae: 0.0218 - val_loss: 0.0018 - val_mae: 0.0309\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.4656e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0301\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.6787e-04 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0302\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.3332e-04 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0292\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.6964e-04 - mae: 0.0197 - val_loss: 0.0019 - val_mae: 0.0310\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.9249e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0284\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.6851e-04 - mae: 0.0183 - val_loss: 0.0016 - val_mae: 0.0282\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.7442e-04 - mae: 0.0197 - val_loss: 0.0017 - val_mae: 0.0293\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.2728e-04 - mae: 0.0189 - val_loss: 0.0016 - val_mae: 0.0283\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.1712e-04 - mae: 0.0193 - val_loss: 0.0019 - val_mae: 0.0317\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.7825e-04 - mae: 0.0180 - val_loss: 0.0014 - val_mae: 0.0267\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.3302e-04 - mae: 0.0192 - val_loss: 0.0015 - val_mae: 0.0278\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.4681e-04 - mae: 0.0175 - val_loss: 0.0018 - val_mae: 0.0301\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.4932e-04 - mae: 0.0175 - val_loss: 0.0027 - val_mae: 0.0405\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.3552e-04 - mae: 0.0176 - val_loss: 0.0015 - val_mae: 0.0279\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.8873e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.8408e-04 - mae: 0.0183 - val_loss: 0.0013 - val_mae: 0.0250\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.3487e-04 - mae: 0.0179 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.6041e-04 - mae: 0.0177 - val_loss: 0.0022 - val_mae: 0.0365\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.3118e-04 - mae: 0.0174 - val_loss: 0.0014 - val_mae: 0.0265\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.1446e-04 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 5.3376e-04 - mae: 0.0172 - val_loss: 0.0013 - val_mae: 0.0258\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.9506e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 5.1240e-04 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8115e-04 - mae: 0.0162 - val_loss: 0.0019 - val_mae: 0.0333\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.4656e-04 - mae: 0.0159 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.9104e-04 - mae: 0.0163 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.7470e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0225\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.1563e-04 - mae: 0.0168 - val_loss: 0.0021 - val_mae: 0.0362\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.6690e-04 - mae: 0.0164 - val_loss: 9.3879e-04 - val_mae: 0.0221\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.1570e-04 - mae: 0.0149 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.4317e-04 - mae: 0.0161 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.3238e-04 - mae: 0.0160 - val_loss: 0.0021 - val_mae: 0.0370\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1474e-04 - mae: 0.0155 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.2669e-04 - mae: 0.0175 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.0475e-04 - mae: 0.0154 - val_loss: 0.0013 - val_mae: 0.0264\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.2630e-04 - mae: 0.0152 - val_loss: 8.5478e-04 - val_mae: 0.0219\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0278e-04 - mae: 0.0150 - val_loss: 0.0017 - val_mae: 0.0317\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0225e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0487 - mae: 0.1744 - val_loss: 0.0180 - val_mae: 0.1131\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0087 - val_mae: 0.0750\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 0.0069 - val_mae: 0.0669\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0312 - val_loss: 0.0046 - val_mae: 0.0535\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0293 - val_loss: 0.0042 - val_mae: 0.0523\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0035 - val_mae: 0.0473\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0023 - val_mae: 0.0363\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0025 - val_mae: 0.0386\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0024 - val_mae: 0.0381\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0023 - val_mae: 0.0378\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0026 - val_mae: 0.0409\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8667e-04 - mae: 0.0246 - val_loss: 0.0018 - val_mae: 0.0319\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0021 - val_mae: 0.0360\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0016 - val_mae: 0.0309\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.3203e-04 - mae: 0.0238 - val_loss: 0.0019 - val_mae: 0.0340\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.0640e-04 - mae: 0.0239 - val_loss: 0.0016 - val_mae: 0.0303\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0019 - val_mae: 0.0344\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.8472e-04 - mae: 0.0233 - val_loss: 0.0019 - val_mae: 0.0347\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.2697e-04 - mae: 0.0235 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.7319e-04 - mae: 0.0231 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.3254e-04 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.5010e-04 - mae: 0.0219 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.4485e-04 - mae: 0.0222 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.3380e-04 - mae: 0.0226 - val_loss: 0.0013 - val_mae: 0.0281\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 8.0082e-04 - mae: 0.0217 - val_loss: 0.0011 - val_mae: 0.0246\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.6569e-04 - mae: 0.0216 - val_loss: 0.0012 - val_mae: 0.0261\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.6690e-04 - mae: 0.0217 - val_loss: 0.0012 - val_mae: 0.0260\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.5445e-04 - mae: 0.0226 - val_loss: 0.0011 - val_mae: 0.0244\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.5417e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 7.6659e-04 - mae: 0.0216 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 8.3145e-04 - mae: 0.0223 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.5372e-04 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.3347e-04 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0233\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 7.9643e-04 - mae: 0.0216 - val_loss: 0.0010 - val_mae: 0.0238\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.9700e-04 - mae: 0.0203 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.8506e-04 - mae: 0.0204 - val_loss: 0.0010 - val_mae: 0.0238\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.4209e-04 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.1589e-04 - mae: 0.0209 - val_loss: 0.0010 - val_mae: 0.0240\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.6390e-04 - mae: 0.0200 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.4242e-04 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0247\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.5806e-04 - mae: 0.0196 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9561e-04 - mae: 0.0204 - val_loss: 9.9247e-04 - val_mae: 0.0229\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.5043e-04 - mae: 0.0199 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.4958e-04 - mae: 0.0195 - val_loss: 9.8037e-04 - val_mae: 0.0225\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.1604e-04 - mae: 0.0192 - val_loss: 9.8410e-04 - val_mae: 0.0226\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.1060e-04 - mae: 0.0190 - val_loss: 0.0012 - val_mae: 0.0266\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.1288e-04 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0231\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.8083e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.3540e-04 - mae: 0.0197 - val_loss: 0.0011 - val_mae: 0.0254\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0415 - mae: 0.1510 - val_loss: 0.0209 - val_mae: 0.1373\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.0025 - val_mae: 0.0427\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.2913e-04 - mae: 0.0192 - val_loss: 0.0021 - val_mae: 0.0385\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.5842e-04 - mae: 0.0182 - val_loss: 0.0020 - val_mae: 0.0377\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.5695e-04 - mae: 0.0186 - val_loss: 0.0018 - val_mae: 0.0349\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.9288e-04 - mae: 0.0173 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.7126e-04 - mae: 0.0169 - val_loss: 0.0016 - val_mae: 0.0327\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.0235e-04 - mae: 0.0176 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.3411e-04 - mae: 0.0162 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.4004e-04 - mae: 0.0164 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.3149e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.7492e-04 - mae: 0.0152 - val_loss: 9.9154e-04 - val_mae: 0.0239\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.1689e-04 - mae: 0.0155 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.7977e-04 - mae: 0.0153 - val_loss: 0.0012 - val_mae: 0.0291\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.6066e-04 - mae: 0.0148 - val_loss: 0.0011 - val_mae: 0.0276\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.5729e-04 - mae: 0.0145 - val_loss: 9.9517e-04 - val_mae: 0.0249\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4092e-04 - mae: 0.0143 - val_loss: 8.6580e-04 - val_mae: 0.0220\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.8889e-04 - mae: 0.0156 - val_loss: 9.5367e-04 - val_mae: 0.0242\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7318e-04 - mae: 0.0150 - val_loss: 8.6095e-04 - val_mae: 0.0222\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.8374e-04 - mae: 0.0149 - val_loss: 8.4484e-04 - val_mae: 0.0219\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.3564e-04 - mae: 0.0143 - val_loss: 7.9437e-04 - val_mae: 0.0194\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.4828e-04 - mae: 0.0144 - val_loss: 9.2838e-04 - val_mae: 0.0240\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.7603e-04 - mae: 0.0150 - val_loss: 0.0014 - val_mae: 0.0315\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.0291e-04 - mae: 0.0133 - val_loss: 8.0005e-04 - val_mae: 0.0212\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.1869e-04 - mae: 0.0139 - val_loss: 8.9806e-04 - val_mae: 0.0235\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1990e-04 - mae: 0.0136 - val_loss: 0.0011 - val_mae: 0.0273\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2486e-04 - mae: 0.0142 - val_loss: 7.1836e-04 - val_mae: 0.0183\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.0752e-04 - mae: 0.0135 - val_loss: 7.0215e-04 - val_mae: 0.0188\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.0784e-04 - mae: 0.0135 - val_loss: 9.0173e-04 - val_mae: 0.0238\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9349e-04 - mae: 0.0131 - val_loss: 8.6980e-04 - val_mae: 0.0232\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.9575e-04 - mae: 0.0133 - val_loss: 6.7293e-04 - val_mae: 0.0178\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.2055e-04 - mae: 0.0138 - val_loss: 6.7314e-04 - val_mae: 0.0176\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3156e-04 - mae: 0.0141 - val_loss: 7.0508e-04 - val_mae: 0.0179\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.0757e-04 - mae: 0.0132 - val_loss: 7.5542e-04 - val_mae: 0.0209\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3710e-04 - mae: 0.0141 - val_loss: 6.5037e-04 - val_mae: 0.0177\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.6693e-04 - mae: 0.0126 - val_loss: 7.6501e-04 - val_mae: 0.0212\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.8780e-04 - mae: 0.0134 - val_loss: 6.6308e-04 - val_mae: 0.0185\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.7496e-04 - mae: 0.0129 - val_loss: 0.0017 - val_mae: 0.0367\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.0931e-04 - mae: 0.0139 - val_loss: 6.5443e-04 - val_mae: 0.0170\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.0013e-04 - mae: 0.0132 - val_loss: 6.2976e-04 - val_mae: 0.0176\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.8759e-04 - mae: 0.0132 - val_loss: 6.3089e-04 - val_mae: 0.0176\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.7514e-04 - mae: 0.0127 - val_loss: 8.6696e-04 - val_mae: 0.0236\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.6952e-04 - mae: 0.0126 - val_loss: 6.2321e-04 - val_mae: 0.0176\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5465e-04 - mae: 0.0125 - val_loss: 9.2901e-04 - val_mae: 0.0249\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.6279e-04 - mae: 0.0123 - val_loss: 8.3172e-04 - val_mae: 0.0232\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.7467e-04 - mae: 0.0127 - val_loss: 7.8113e-04 - val_mae: 0.0221\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.6944e-04 - mae: 0.0126 - val_loss: 6.3838e-04 - val_mae: 0.0188\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 2.6133e-04 - mae: 0.0123 - val_loss: 7.8324e-04 - val_mae: 0.0222\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 2.4772e-04 - mae: 0.0122 - val_loss: 5.8088e-04 - val_mae: 0.0161\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.7600e-04 - mae: 0.0131 - val_loss: 6.8976e-04 - val_mae: 0.0200\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0552 - mae: 0.1694 - val_loss: 0.0430 - val_mae: 0.1973\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0036 - val_mae: 0.0531\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.0136e-04 - mae: 0.0219 - val_loss: 0.0025 - val_mae: 0.0416\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.4608e-04 - mae: 0.0218 - val_loss: 0.0034 - val_mae: 0.0521\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.2444e-04 - mae: 0.0216 - val_loss: 0.0025 - val_mae: 0.0424\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.2630e-04 - mae: 0.0196 - val_loss: 0.0027 - val_mae: 0.0455\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.6319e-04 - mae: 0.0205 - val_loss: 0.0020 - val_mae: 0.0370\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.9201e-04 - mae: 0.0192 - val_loss: 0.0015 - val_mae: 0.0311\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.7121e-04 - mae: 0.0187 - val_loss: 0.0018 - val_mae: 0.0354\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.4517e-04 - mae: 0.0184 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.5524e-04 - mae: 0.0187 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 5.0550e-04 - mae: 0.0175 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 4.7630e-04 - mae: 0.0173 - val_loss: 0.0016 - val_mae: 0.0344\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.5510e-04 - mae: 0.0168 - val_loss: 0.0014 - val_mae: 0.0315\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.4246e-04 - mae: 0.0165 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.4909e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0258\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.2165e-04 - mae: 0.0161 - val_loss: 0.0014 - val_mae: 0.0317\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.4533e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0293\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9642e-04 - mae: 0.0156 - val_loss: 9.0529e-04 - val_mae: 0.0236\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1850e-04 - mae: 0.0161 - val_loss: 9.7649e-04 - val_mae: 0.0253\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7090e-04 - mae: 0.0149 - val_loss: 9.7163e-04 - val_mae: 0.0254\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.7573e-04 - mae: 0.0152 - val_loss: 0.0010 - val_mae: 0.0261\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.7436e-04 - mae: 0.0154 - val_loss: 8.3572e-04 - val_mae: 0.0225\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.6407e-04 - mae: 0.0152 - val_loss: 7.7284e-04 - val_mae: 0.0210\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.7796e-04 - mae: 0.0156 - val_loss: 8.4039e-04 - val_mae: 0.0230\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.6478e-04 - mae: 0.0149 - val_loss: 7.2211e-04 - val_mae: 0.0197\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4066e-04 - mae: 0.0144 - val_loss: 7.1500e-04 - val_mae: 0.0195\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.3308e-04 - mae: 0.0143 - val_loss: 9.8423e-04 - val_mae: 0.0260\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 3.3752e-04 - mae: 0.0146 - val_loss: 7.2090e-04 - val_mae: 0.0202\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 3.4727e-04 - mae: 0.0146 - val_loss: 6.8196e-04 - val_mae: 0.0188\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3685e-04 - mae: 0.0145 - val_loss: 7.9369e-04 - val_mae: 0.0223\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1809e-04 - mae: 0.0139 - val_loss: 9.0339e-04 - val_mae: 0.0225\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3762e-04 - mae: 0.0143 - val_loss: 9.0553e-04 - val_mae: 0.0247\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2085e-04 - mae: 0.0141 - val_loss: 6.9666e-04 - val_mae: 0.0199\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1452e-04 - mae: 0.0139 - val_loss: 7.1843e-04 - val_mae: 0.0187\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9883e-04 - mae: 0.0135 - val_loss: 6.5756e-04 - val_mae: 0.0177\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9521e-04 - mae: 0.0136 - val_loss: 6.7750e-04 - val_mae: 0.0180\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.2391e-04 - mae: 0.0140 - val_loss: 6.3259e-04 - val_mae: 0.0180\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.4027e-04 - mae: 0.0144 - val_loss: 6.2608e-04 - val_mae: 0.0178\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.8880e-04 - mae: 0.0134 - val_loss: 6.2606e-04 - val_mae: 0.0180\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.7837e-04 - mae: 0.0131 - val_loss: 7.7664e-04 - val_mae: 0.0223\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.9309e-04 - mae: 0.0139 - val_loss: 9.6428e-04 - val_mae: 0.0261\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.9129e-04 - mae: 0.0134 - val_loss: 6.6671e-04 - val_mae: 0.0198\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.9687e-04 - mae: 0.0137 - val_loss: 7.1260e-04 - val_mae: 0.0210\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5876e-04 - mae: 0.0124 - val_loss: 7.8709e-04 - val_mae: 0.0228\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 2.7065e-04 - mae: 0.0131 - val_loss: 6.4681e-04 - val_mae: 0.0194\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.8418e-04 - mae: 0.0130 - val_loss: 5.9396e-04 - val_mae: 0.0174\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5809e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.2653e-04 - mae: 0.0143 - val_loss: 8.6926e-04 - val_mae: 0.0244\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.8437e-04 - mae: 0.0131 - val_loss: 6.6865e-04 - val_mae: 0.0200\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0587 - mae: 0.1801 - val_loss: 0.0321 - val_mae: 0.1706\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0057 - val_mae: 0.0693\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.9433e-04 - mae: 0.0224 - val_loss: 0.0019 - val_mae: 0.0336\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.4480e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0315\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.2055e-04 - mae: 0.0194 - val_loss: 0.0021 - val_mae: 0.0386\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.8231e-04 - mae: 0.0203 - val_loss: 0.0016 - val_mae: 0.0310\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.1735e-04 - mae: 0.0194 - val_loss: 0.0015 - val_mae: 0.0288\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.0187e-04 - mae: 0.0191 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.7096e-04 - mae: 0.0189 - val_loss: 0.0012 - val_mae: 0.0233\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.6796e-04 - mae: 0.0185 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 5.1892e-04 - mae: 0.0177 - val_loss: 0.0013 - val_mae: 0.0285\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.1832e-04 - mae: 0.0177 - val_loss: 0.0013 - val_mae: 0.0284\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.3019e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mae: 0.0236\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.3795e-04 - mae: 0.0180 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.8226e-04 - mae: 0.0171 - val_loss: 8.9963e-04 - val_mae: 0.0205\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.9217e-04 - mae: 0.0171 - val_loss: 8.6567e-04 - val_mae: 0.0206\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.1970e-04 - mae: 0.0159 - val_loss: 9.1790e-04 - val_mae: 0.0232\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.5797e-04 - mae: 0.0167 - val_loss: 8.1253e-04 - val_mae: 0.0203\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.7477e-04 - mae: 0.0152 - val_loss: 7.8526e-04 - val_mae: 0.0199\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.3246e-04 - mae: 0.0161 - val_loss: 7.6138e-04 - val_mae: 0.0195\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.2389e-04 - mae: 0.0161 - val_loss: 7.6425e-04 - val_mae: 0.0188\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.0272e-04 - mae: 0.0157 - val_loss: 7.4533e-04 - val_mae: 0.0199\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.4027e-04 - mae: 0.0159 - val_loss: 7.2221e-04 - val_mae: 0.0194\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1318e-04 - mae: 0.0155 - val_loss: 8.1001e-04 - val_mae: 0.0223\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.0366e-04 - mae: 0.0155 - val_loss: 6.9191e-04 - val_mae: 0.0185\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9312e-04 - mae: 0.0150 - val_loss: 6.9056e-04 - val_mae: 0.0189\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.8527e-04 - mae: 0.0153 - val_loss: 6.8857e-04 - val_mae: 0.0189\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 4.1122e-04 - mae: 0.0155 - val_loss: 8.7135e-04 - val_mae: 0.0209\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 3.3857e-04 - mae: 0.0145 - val_loss: 8.5609e-04 - val_mae: 0.0206\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.6565e-04 - mae: 0.0149 - val_loss: 6.5995e-04 - val_mae: 0.0179\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.6799e-04 - mae: 0.0146 - val_loss: 6.5599e-04 - val_mae: 0.0178\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3718e-04 - mae: 0.0143 - val_loss: 7.2033e-04 - val_mae: 0.0181\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3546e-04 - mae: 0.0142 - val_loss: 6.8985e-04 - val_mae: 0.0194\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3957e-04 - mae: 0.0142 - val_loss: 7.3658e-04 - val_mae: 0.0184\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3296e-04 - mae: 0.0140 - val_loss: 7.1841e-04 - val_mae: 0.0203\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4217e-04 - mae: 0.0142 - val_loss: 7.7001e-04 - val_mae: 0.0191\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1182e-04 - mae: 0.0138 - val_loss: 7.4012e-04 - val_mae: 0.0209\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1219e-04 - mae: 0.0134 - val_loss: 6.3663e-04 - val_mae: 0.0171\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1687e-04 - mae: 0.0138 - val_loss: 6.8418e-04 - val_mae: 0.0175\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.6097e-04 - mae: 0.0146 - val_loss: 6.3106e-04 - val_mae: 0.0173\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3032e-04 - mae: 0.0140 - val_loss: 7.1699e-04 - val_mae: 0.0202\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9614e-04 - mae: 0.0133 - val_loss: 6.7312e-04 - val_mae: 0.0172\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9606e-04 - mae: 0.0133 - val_loss: 0.0013 - val_mae: 0.0315\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1442e-04 - mae: 0.0137 - val_loss: 6.1991e-04 - val_mae: 0.0169\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9700e-04 - mae: 0.0136 - val_loss: 6.4920e-04 - val_mae: 0.0184\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.0152e-04 - mae: 0.0136 - val_loss: 6.3603e-04 - val_mae: 0.0180\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 3.0564e-04 - mae: 0.0135 - val_loss: 7.8583e-04 - val_mae: 0.0196\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.1019e-04 - mae: 0.0132 - val_loss: 6.1407e-04 - val_mae: 0.0167\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9605e-04 - mae: 0.0135 - val_loss: 6.2717e-04 - val_mae: 0.0174\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.9397e-04 - mae: 0.0134 - val_loss: 6.5560e-04 - val_mae: 0.0169\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0399 - mae: 0.1412 - val_loss: 0.0275 - val_mae: 0.1591\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0044 - val_mae: 0.0610\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.1392e-04 - mae: 0.0177 - val_loss: 0.0014 - val_mae: 0.0296\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.8568e-04 - mae: 0.0173 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.6248e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0267\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.0205e-04 - mae: 0.0155 - val_loss: 0.0012 - val_mae: 0.0264\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.5648e-04 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0240\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1660e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mae: 0.0241\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9122e-04 - mae: 0.0153 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.0884e-04 - mae: 0.0159 - val_loss: 0.0013 - val_mae: 0.0301\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 4.1234e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 3.9794e-04 - mae: 0.0153 - val_loss: 0.0012 - val_mae: 0.0296\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 3.7185e-04 - mae: 0.0149 - val_loss: 8.1591e-04 - val_mae: 0.0197\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.9724e-04 - mae: 0.0156 - val_loss: 0.0014 - val_mae: 0.0327\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.8675e-04 - mae: 0.0156 - val_loss: 7.9310e-04 - val_mae: 0.0202\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3359e-04 - mae: 0.0140 - val_loss: 8.7346e-04 - val_mae: 0.0229\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3477e-04 - mae: 0.0144 - val_loss: 8.4904e-04 - val_mae: 0.0224\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.4180e-04 - mae: 0.0140 - val_loss: 0.0012 - val_mae: 0.0303\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.9241e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mae: 0.0279\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.3809e-04 - mae: 0.0142 - val_loss: 7.5497e-04 - val_mae: 0.0204\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.1683e-04 - mae: 0.0137 - val_loss: 7.0156e-04 - val_mae: 0.0186\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.1515e-04 - mae: 0.0138 - val_loss: 6.8547e-04 - val_mae: 0.0182\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.3922e-04 - mae: 0.0142 - val_loss: 9.2446e-04 - val_mae: 0.0249\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.3121e-04 - mae: 0.0141 - val_loss: 6.7506e-04 - val_mae: 0.0184\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.2144e-04 - mae: 0.0139 - val_loss: 6.7173e-04 - val_mae: 0.0185\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 3.2429e-04 - mae: 0.0139 - val_loss: 7.8305e-04 - val_mae: 0.0219\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 2.8364e-04 - mae: 0.0133 - val_loss: 8.3867e-04 - val_mae: 0.0234\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.9144e-04 - mae: 0.0130 - val_loss: 6.6536e-04 - val_mae: 0.0188\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.2248e-04 - mae: 0.0133 - val_loss: 6.2814e-04 - val_mae: 0.0173\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.0375e-04 - mae: 0.0132 - val_loss: 6.3153e-04 - val_mae: 0.0179\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.7852e-04 - mae: 0.0129 - val_loss: 9.4481e-04 - val_mae: 0.0258\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.1364e-04 - mae: 0.0138 - val_loss: 7.6097e-04 - val_mae: 0.0218\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.8964e-04 - mae: 0.0128 - val_loss: 6.5330e-04 - val_mae: 0.0190\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.1964e-04 - mae: 0.0138 - val_loss: 8.0177e-04 - val_mae: 0.0230\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.7235e-04 - mae: 0.0125 - val_loss: 7.0654e-04 - val_mae: 0.0207\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.6413e-04 - mae: 0.0126 - val_loss: 5.8431e-04 - val_mae: 0.0161\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0779e-04 - mae: 0.0133 - val_loss: 6.4339e-04 - val_mae: 0.0170\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.6111e-04 - mae: 0.0125 - val_loss: 6.4052e-04 - val_mae: 0.0192\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4460e-04 - mae: 0.0121 - val_loss: 6.2503e-04 - val_mae: 0.0187\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.4559e-04 - mae: 0.0120 - val_loss: 6.1596e-04 - val_mae: 0.0186\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 2.6904e-04 - mae: 0.0126 - val_loss: 5.5867e-04 - val_mae: 0.0159\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 2.5443e-04 - mae: 0.0123 - val_loss: 5.5247e-04 - val_mae: 0.0157\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5032e-04 - mae: 0.0121 - val_loss: 5.5678e-04 - val_mae: 0.0167\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4212e-04 - mae: 0.0118 - val_loss: 5.9376e-04 - val_mae: 0.0183\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.6138e-04 - mae: 0.0125 - val_loss: 5.3828e-04 - val_mae: 0.0162\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4772e-04 - mae: 0.0122 - val_loss: 5.3088e-04 - val_mae: 0.0158\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4321e-04 - mae: 0.0120 - val_loss: 6.1745e-04 - val_mae: 0.0167\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.8256e-04 - mae: 0.0126 - val_loss: 6.8303e-04 - val_mae: 0.0208\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.4649e-04 - mae: 0.0121 - val_loss: 5.6791e-04 - val_mae: 0.0177\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.3034e-04 - mae: 0.0116 - val_loss: 5.1096e-04 - val_mae: 0.0155\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0297 - mae: 0.1270 - val_loss: 0.0071 - val_mae: 0.0722\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0028 - val_mae: 0.0392\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0021 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0383\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0024 - val_mae: 0.0367\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - mae: 0.0348 - val_loss: 0.0027 - val_mae: 0.0423\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0020 - mae: 0.0349 - val_loss: 0.0022 - val_mae: 0.0374\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0346\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0018 - val_mae: 0.0329\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0017 - val_mae: 0.0323\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 0.0016 - val_mae: 0.0309\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0019 - val_mae: 0.0353\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0335\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0361\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0015 - val_mae: 0.0304\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0015 - val_mae: 0.0303\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0015 - val_mae: 0.0292\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - mae: 0.0316 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0341\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0017 - val_mae: 0.0326\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0275\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0270 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0013 - val_mae: 0.0284\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0265 - val_loss: 0.0013 - val_mae: 0.0283\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0267 - val_loss: 0.0012 - val_mae: 0.0268\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0267 - val_loss: 0.0016 - val_mae: 0.0320\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0286\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0013 - val_mae: 0.0276\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0012 - val_mae: 0.0268\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.6572e-04 - mae: 0.0246 - val_loss: 0.0021 - val_mae: 0.0376\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0252\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0253\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0015 - val_mae: 0.0305\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.8943e-04 - mae: 0.0252 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8823e-04 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0252\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0262\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - mae: 0.0254 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0250\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.6903e-04 - mae: 0.0247 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.9715e-04 - mae: 0.0251 - val_loss: 0.0016 - val_mae: 0.0319\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.4112e-04 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.8142e-04 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0413 - mae: 0.1537 - val_loss: 0.0178 - val_mae: 0.1273\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0033 - val_mae: 0.0506\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.3405e-04 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.0719e-04 - mae: 0.0208 - val_loss: 0.0014 - val_mae: 0.0251\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.3072e-04 - mae: 0.0209 - val_loss: 0.0013 - val_mae: 0.0249\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.2319e-04 - mae: 0.0197 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.2475e-04 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.2624e-04 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0237\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.5610e-04 - mae: 0.0183 - val_loss: 0.0012 - val_mae: 0.0261\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.3865e-04 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0242\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.6241e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.6908e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mae: 0.0239\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 5.7790e-04 - mae: 0.0184 - val_loss: 0.0015 - val_mae: 0.0279\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.3777e-04 - mae: 0.0176 - val_loss: 9.3111e-04 - val_mae: 0.0216\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.5297e-04 - mae: 0.0179 - val_loss: 9.4164e-04 - val_mae: 0.0226\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.7942e-04 - mae: 0.0169 - val_loss: 9.2679e-04 - val_mae: 0.0210\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 4.8857e-04 - mae: 0.0171 - val_loss: 0.0019 - val_mae: 0.0347\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.0920e-04 - mae: 0.0172 - val_loss: 8.6783e-04 - val_mae: 0.0204\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.8835e-04 - mae: 0.0166 - val_loss: 8.8076e-04 - val_mae: 0.0203\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.5625e-04 - mae: 0.0161 - val_loss: 8.6856e-04 - val_mae: 0.0202\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.3543e-04 - mae: 0.0158 - val_loss: 8.6319e-04 - val_mae: 0.0201\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.1203e-04 - mae: 0.0154 - val_loss: 9.1554e-04 - val_mae: 0.0211\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.5102e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mae: 0.0246\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.8836e-04 - mae: 0.0149 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.1037e-04 - mae: 0.0152 - val_loss: 7.9559e-04 - val_mae: 0.0200\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.4221e-04 - mae: 0.0166 - val_loss: 7.8667e-04 - val_mae: 0.0193\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.9533e-04 - mae: 0.0153 - val_loss: 9.1970e-04 - val_mae: 0.0213\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.9598e-04 - mae: 0.0154 - val_loss: 8.3820e-04 - val_mae: 0.0200\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.6378e-04 - mae: 0.0145 - val_loss: 9.9354e-04 - val_mae: 0.0225\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.8983e-04 - mae: 0.0154 - val_loss: 7.5502e-04 - val_mae: 0.0189\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3.9556e-04 - mae: 0.0154 - val_loss: 8.2129e-04 - val_mae: 0.0198\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.9231e-04 - mae: 0.0152 - val_loss: 7.6711e-04 - val_mae: 0.0203\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.8706e-04 - mae: 0.0150 - val_loss: 8.9591e-04 - val_mae: 0.0209\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.0367e-04 - mae: 0.0154 - val_loss: 7.3574e-04 - val_mae: 0.0194\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.8679e-04 - mae: 0.0154 - val_loss: 8.3097e-04 - val_mae: 0.0222\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.0333e-04 - mae: 0.0157 - val_loss: 9.0249e-04 - val_mae: 0.0210\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.3004e-04 - mae: 0.0139 - val_loss: 7.0793e-04 - val_mae: 0.0180\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0765e-04 - mae: 0.0135 - val_loss: 9.3155e-04 - val_mae: 0.0215\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.6084e-04 - mae: 0.0147 - val_loss: 7.3410e-04 - val_mae: 0.0181\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.3346e-04 - mae: 0.0141 - val_loss: 6.8979e-04 - val_mae: 0.0178\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.5069e-04 - mae: 0.0143 - val_loss: 6.8784e-04 - val_mae: 0.0184\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0828e-04 - mae: 0.0134 - val_loss: 8.7003e-04 - val_mae: 0.0204\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.3717e-04 - mae: 0.0141 - val_loss: 7.3083e-04 - val_mae: 0.0179\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 3.2201e-04 - mae: 0.0138 - val_loss: 7.0783e-04 - val_mae: 0.0195\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4.0821e-04 - mae: 0.0159 - val_loss: 0.0012 - val_mae: 0.0269\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.6471e-04 - mae: 0.0150 - val_loss: 6.6084e-04 - val_mae: 0.0172\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3541e-04 - mae: 0.0141 - val_loss: 7.6461e-04 - val_mae: 0.0212\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9473e-04 - mae: 0.0132 - val_loss: 7.2550e-04 - val_mae: 0.0177\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.1240e-04 - mae: 0.0134 - val_loss: 7.0172e-04 - val_mae: 0.0173\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1603e-04 - mae: 0.0134 - val_loss: 6.4595e-04 - val_mae: 0.0169\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0275 - mae: 0.1204 - val_loss: 0.0458 - val_mae: 0.2033\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.6920e-04 - mae: 0.0226 - val_loss: 0.0018 - val_mae: 0.0311\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.3974e-04 - mae: 0.0135 - val_loss: 0.0015 - val_mae: 0.0287\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5221e-04 - mae: 0.0121 - val_loss: 0.0013 - val_mae: 0.0280\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2084e-04 - mae: 0.0114 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 2.1707e-04 - mae: 0.0112 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 2.0148e-04 - mae: 0.0109 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.0639e-04 - mae: 0.0110 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5977e-04 - mae: 0.0100 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.5922e-04 - mae: 0.0098 - val_loss: 0.0011 - val_mae: 0.0273\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6768e-04 - mae: 0.0101 - val_loss: 0.0018 - val_mae: 0.0349\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7514e-04 - mae: 0.0104 - val_loss: 9.4215e-04 - val_mae: 0.0244\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6065e-04 - mae: 0.0100 - val_loss: 9.9891e-04 - val_mae: 0.0251\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.4605e-04 - mae: 0.0093 - val_loss: 0.0010 - val_mae: 0.0256\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4516e-04 - mae: 0.0094 - val_loss: 8.1234e-04 - val_mae: 0.0219\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.4951e-04 - mae: 0.0096 - val_loss: 7.7078e-04 - val_mae: 0.0211\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.2756e-04 - mae: 0.0088 - val_loss: 6.8775e-04 - val_mae: 0.0197\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.3345e-04 - mae: 0.0091 - val_loss: 7.1962e-04 - val_mae: 0.0201\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.3611e-04 - mae: 0.0092 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1884e-04 - mae: 0.0084 - val_loss: 9.6545e-04 - val_mae: 0.0235\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.1961e-04 - mae: 0.0085 - val_loss: 8.2056e-04 - val_mae: 0.0213\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.3376e-04 - mae: 0.0090 - val_loss: 0.0010 - val_mae: 0.0241\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.2098e-04 - mae: 0.0086 - val_loss: 6.1424e-04 - val_mae: 0.0182\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.3091e-04 - mae: 0.0090 - val_loss: 9.1253e-04 - val_mae: 0.0226\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.2213e-04 - mae: 0.0087 - val_loss: 7.1237e-04 - val_mae: 0.0194\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0175e-04 - mae: 0.0079 - val_loss: 5.8771e-04 - val_mae: 0.0177\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1045e-04 - mae: 0.0081 - val_loss: 5.9891e-04 - val_mae: 0.0177\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.9407e-05 - mae: 0.0078 - val_loss: 6.3814e-04 - val_mae: 0.0182\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0012e-04 - mae: 0.0078 - val_loss: 5.7402e-04 - val_mae: 0.0175\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.0282e-04 - mae: 0.0080 - val_loss: 5.8814e-04 - val_mae: 0.0176\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.6752e-05 - mae: 0.0076 - val_loss: 5.8521e-04 - val_mae: 0.0184\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.6965e-05 - mae: 0.0077 - val_loss: 5.3990e-04 - val_mae: 0.0174\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.0105e-04 - mae: 0.0078 - val_loss: 5.9683e-04 - val_mae: 0.0178\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 9.7844e-05 - mae: 0.0078 - val_loss: 5.6822e-04 - val_mae: 0.0181\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 9.1852e-05 - mae: 0.0074 - val_loss: 5.8205e-04 - val_mae: 0.0176\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.8245e-05 - mae: 0.0073 - val_loss: 5.3389e-04 - val_mae: 0.0169\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.5483e-05 - mae: 0.0072 - val_loss: 5.4062e-04 - val_mae: 0.0170\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.6533e-05 - mae: 0.0073 - val_loss: 5.1966e-04 - val_mae: 0.0167\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 8.8007e-05 - mae: 0.0072 - val_loss: 5.3318e-04 - val_mae: 0.0169\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 7.8228e-05 - mae: 0.0069 - val_loss: 5.1095e-04 - val_mae: 0.0164\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.4782e-05 - mae: 0.0068 - val_loss: 6.7083e-04 - val_mae: 0.0197\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.6255e-05 - mae: 0.0072 - val_loss: 6.4663e-04 - val_mae: 0.0188\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 9.2450e-05 - mae: 0.0074 - val_loss: 5.4937e-04 - val_mae: 0.0174\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.2976e-05 - mae: 0.0070 - val_loss: 5.2999e-04 - val_mae: 0.0167\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.6040e-05 - mae: 0.0067 - val_loss: 4.9837e-04 - val_mae: 0.0161\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.6569e-05 - mae: 0.0072 - val_loss: 7.2245e-04 - val_mae: 0.0201\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.0295e-05 - mae: 0.0073 - val_loss: 4.8948e-04 - val_mae: 0.0160\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.8552e-05 - mae: 0.0068 - val_loss: 5.2494e-04 - val_mae: 0.0167\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.2619e-05 - mae: 0.0066 - val_loss: 5.7361e-04 - val_mae: 0.0175\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.6425e-05 - mae: 0.0066 - val_loss: 5.0107e-04 - val_mae: 0.0163\n",
            "Epoch 1/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1859 - mae: 0.3157 - val_loss: 0.0011 - val_mae: 0.0288\n",
            "Epoch 2/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0448 - val_loss: 3.7292e-04 - val_mae: 0.0154\n",
            "Epoch 3/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 3.8719e-04 - val_mae: 0.0155\n",
            "Epoch 4/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 9.7126e-04 - mae: 0.0248 - val_loss: 3.6245e-04 - val_mae: 0.0149\n",
            "Epoch 5/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.5100e-04 - mae: 0.0239 - val_loss: 3.4770e-04 - val_mae: 0.0146\n",
            "Epoch 6/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.9739e-04 - mae: 0.0241 - val_loss: 3.5886e-04 - val_mae: 0.0147\n",
            "Epoch 7/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.7582e-04 - mae: 0.0236 - val_loss: 3.4302e-04 - val_mae: 0.0144\n",
            "Epoch 8/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.1427e-04 - mae: 0.0231 - val_loss: 3.3792e-04 - val_mae: 0.0144\n",
            "Epoch 9/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.9026e-04 - mae: 0.0243 - val_loss: 3.3867e-04 - val_mae: 0.0143\n",
            "Epoch 10/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.9457e-04 - mae: 0.0229 - val_loss: 3.4890e-04 - val_mae: 0.0151\n",
            "Epoch 11/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.0029e-04 - mae: 0.0226 - val_loss: 3.2788e-04 - val_mae: 0.0142\n",
            "Epoch 12/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.7977e-04 - mae: 0.0225 - val_loss: 3.2499e-04 - val_mae: 0.0141\n",
            "Epoch 13/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.5086e-04 - mae: 0.0220 - val_loss: 3.2461e-04 - val_mae: 0.0141\n",
            "Epoch 14/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 7.8841e-04 - mae: 0.0226 - val_loss: 3.2567e-04 - val_mae: 0.0140\n",
            "Epoch 15/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.7995e-04 - mae: 0.0224 - val_loss: 3.1547e-04 - val_mae: 0.0141\n",
            "Epoch 16/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 7.3281e-04 - mae: 0.0216 - val_loss: 3.1649e-04 - val_mae: 0.0139\n",
            "Epoch 17/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.8035e-04 - mae: 0.0209 - val_loss: 3.0967e-04 - val_mae: 0.0139\n",
            "Epoch 18/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.4949e-04 - mae: 0.0205 - val_loss: 3.0725e-04 - val_mae: 0.0138\n",
            "Epoch 19/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.5621e-04 - mae: 0.0203 - val_loss: 3.0652e-04 - val_mae: 0.0140\n",
            "Epoch 20/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.3600e-04 - mae: 0.0202 - val_loss: 3.1403e-04 - val_mae: 0.0143\n",
            "Epoch 21/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.6568e-04 - mae: 0.0205 - val_loss: 3.0023e-04 - val_mae: 0.0138\n",
            "Epoch 22/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.6827e-04 - mae: 0.0209 - val_loss: 3.2360e-04 - val_mae: 0.0147\n",
            "Epoch 23/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.4401e-04 - mae: 0.0204 - val_loss: 3.0446e-04 - val_mae: 0.0141\n",
            "Epoch 24/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.9638e-04 - mae: 0.0195 - val_loss: 3.0614e-04 - val_mae: 0.0142\n",
            "Epoch 25/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.5892e-04 - mae: 0.0203 - val_loss: 2.9259e-04 - val_mae: 0.0138\n",
            "Epoch 26/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.1407e-04 - mae: 0.0198 - val_loss: 2.8363e-04 - val_mae: 0.0134\n",
            "Epoch 27/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.9906e-04 - mae: 0.0193 - val_loss: 3.1020e-04 - val_mae: 0.0143\n",
            "Epoch 28/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.5944e-04 - mae: 0.0188 - val_loss: 2.7827e-04 - val_mae: 0.0132\n",
            "Epoch 29/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 5.7262e-04 - mae: 0.0191 - val_loss: 3.0478e-04 - val_mae: 0.0142\n",
            "Epoch 30/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 5.8006e-04 - mae: 0.0191 - val_loss: 2.8885e-04 - val_mae: 0.0138\n",
            "Epoch 31/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.6485e-04 - mae: 0.0188 - val_loss: 3.1727e-04 - val_mae: 0.0145\n",
            "Epoch 32/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.8563e-04 - mae: 0.0192 - val_loss: 2.8987e-04 - val_mae: 0.0138\n",
            "Epoch 33/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.8984e-04 - mae: 0.0194 - val_loss: 2.7328e-04 - val_mae: 0.0133\n",
            "Epoch 34/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.0082e-04 - mae: 0.0195 - val_loss: 2.8597e-04 - val_mae: 0.0137\n",
            "Epoch 35/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.4821e-04 - mae: 0.0186 - val_loss: 2.5992e-04 - val_mae: 0.0127\n",
            "Epoch 36/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 5.6723e-04 - mae: 0.0192 - val_loss: 2.5866e-04 - val_mae: 0.0127\n",
            "Epoch 37/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.5561e-04 - mae: 0.0202 - val_loss: 2.8058e-04 - val_mae: 0.0135\n",
            "Epoch 38/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.2773e-04 - mae: 0.0183 - val_loss: 2.5489e-04 - val_mae: 0.0127\n",
            "Epoch 39/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.6097e-04 - mae: 0.0190 - val_loss: 2.6974e-04 - val_mae: 0.0131\n",
            "Epoch 40/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.0977e-04 - mae: 0.0177 - val_loss: 2.6066e-04 - val_mae: 0.0128\n",
            "Epoch 41/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.1970e-04 - mae: 0.0183 - val_loss: 2.4671e-04 - val_mae: 0.0125\n",
            "Epoch 42/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 5.3563e-04 - mae: 0.0185 - val_loss: 3.1878e-04 - val_mae: 0.0145\n",
            "Epoch 43/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.3765e-04 - mae: 0.0185 - val_loss: 2.6604e-04 - val_mae: 0.0130\n",
            "Epoch 44/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 5.7416e-04 - mae: 0.0190 - val_loss: 2.5777e-04 - val_mae: 0.0128\n",
            "Epoch 45/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 4.9095e-04 - mae: 0.0177 - val_loss: 2.5539e-04 - val_mae: 0.0127\n",
            "Epoch 46/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 5.0511e-04 - mae: 0.0178 - val_loss: 2.3630e-04 - val_mae: 0.0121\n",
            "Epoch 47/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.9532e-04 - mae: 0.0175 - val_loss: 2.7630e-04 - val_mae: 0.0133\n",
            "Epoch 48/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.3680e-04 - mae: 0.0187 - val_loss: 2.4466e-04 - val_mae: 0.0124\n",
            "Epoch 49/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 5.4864e-04 - mae: 0.0187 - val_loss: 2.4816e-04 - val_mae: 0.0125\n",
            "Epoch 50/50\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.5496e-04 - mae: 0.0167 - val_loss: 2.2923e-04 - val_mae: 0.0120\n",
            "Epoch 1/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0345 - mae: 0.1293 - val_loss: 0.0015 - val_mae: 0.0305\n",
            "Epoch 2/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - mae: 0.0287 - val_loss: 0.0066 - val_mae: 0.0718\n",
            "Epoch 3/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.8890e-04 - mae: 0.0191 - val_loss: 0.0027 - val_mae: 0.0427\n",
            "Epoch 4/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.9015e-04 - mae: 0.0175 - val_loss: 0.0027 - val_mae: 0.0436\n",
            "Epoch 5/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.0768e-04 - mae: 0.0178 - val_loss: 9.9401e-04 - val_mae: 0.0245\n",
            "Epoch 6/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.2269e-04 - mae: 0.0165 - val_loss: 8.8439e-04 - val_mae: 0.0229\n",
            "Epoch 7/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 5.0836e-04 - mae: 0.0164 - val_loss: 8.2895e-04 - val_mae: 0.0220\n",
            "Epoch 8/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 4.6449e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 9/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 4.1110e-04 - mae: 0.0147 - val_loss: 8.5997e-04 - val_mae: 0.0220\n",
            "Epoch 10/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.0653e-04 - mae: 0.0143 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 11/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.5345e-04 - mae: 0.0135 - val_loss: 8.5490e-04 - val_mae: 0.0221\n",
            "Epoch 12/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.6834e-04 - mae: 0.0141 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 13/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.3517e-04 - mae: 0.0130 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 14/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.2687e-04 - mae: 0.0132 - val_loss: 8.5776e-04 - val_mae: 0.0225\n",
            "Epoch 15/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.9889e-04 - mae: 0.0125 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 16/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.3476e-04 - mae: 0.0128 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 17/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.8847e-04 - mae: 0.0123 - val_loss: 0.0026 - val_mae: 0.0454\n",
            "Epoch 18/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 3.1666e-04 - mae: 0.0126 - val_loss: 0.0026 - val_mae: 0.0455\n",
            "Epoch 19/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9351e-04 - mae: 0.0125 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 20/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.7025e-04 - mae: 0.0119 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 21/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.8683e-04 - mae: 0.0121 - val_loss: 7.6666e-04 - val_mae: 0.0215\n",
            "Epoch 22/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5285e-04 - mae: 0.0115 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 23/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.7329e-04 - mae: 0.0119 - val_loss: 6.3214e-04 - val_mae: 0.0191\n",
            "Epoch 24/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.9807e-04 - mae: 0.0121 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 25/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5330e-04 - mae: 0.0113 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 26/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4030e-04 - mae: 0.0111 - val_loss: 7.4544e-04 - val_mae: 0.0215\n",
            "Epoch 27/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5728e-04 - mae: 0.0113 - val_loss: 6.2970e-04 - val_mae: 0.0194\n",
            "Epoch 28/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.5334e-04 - mae: 0.0112 - val_loss: 0.0016 - val_mae: 0.0350\n",
            "Epoch 29/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 2.1317e-04 - mae: 0.0103 - val_loss: 5.0396e-04 - val_mae: 0.0169\n",
            "Epoch 30/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.1666e-04 - mae: 0.0104 - val_loss: 5.2237e-04 - val_mae: 0.0174\n",
            "Epoch 31/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5609e-04 - mae: 0.0113 - val_loss: 0.0013 - val_mae: 0.0310\n",
            "Epoch 32/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.6138e-04 - mae: 0.0113 - val_loss: 7.6610e-04 - val_mae: 0.0222\n",
            "Epoch 33/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.4822e-04 - mae: 0.0113 - val_loss: 7.9976e-04 - val_mae: 0.0229\n",
            "Epoch 34/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.2293e-04 - mae: 0.0105 - val_loss: 5.4954e-04 - val_mae: 0.0182\n",
            "Epoch 35/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2834e-04 - mae: 0.0105 - val_loss: 8.3546e-04 - val_mae: 0.0236\n",
            "Epoch 36/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.2253e-04 - mae: 0.0103 - val_loss: 9.7274e-04 - val_mae: 0.0259\n",
            "Epoch 37/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3428e-04 - mae: 0.0107 - val_loss: 7.2221e-04 - val_mae: 0.0216\n",
            "Epoch 38/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 2.3737e-04 - mae: 0.0108 - val_loss: 8.5077e-04 - val_mae: 0.0239\n",
            "Epoch 39/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.1909e-04 - mae: 0.0102 - val_loss: 7.3519e-04 - val_mae: 0.0219\n",
            "Epoch 40/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.9991e-04 - mae: 0.0101 - val_loss: 7.1218e-04 - val_mae: 0.0215\n",
            "Epoch 41/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1220e-04 - mae: 0.0102 - val_loss: 0.0011 - val_mae: 0.0285\n",
            "Epoch 42/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3277e-04 - mae: 0.0105 - val_loss: 8.1510e-04 - val_mae: 0.0234\n",
            "Epoch 43/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0262e-04 - mae: 0.0100 - val_loss: 0.0013 - val_mae: 0.0309\n",
            "Epoch 44/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1869e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0298\n",
            "Epoch 45/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.1013e-04 - mae: 0.0098 - val_loss: 5.0871e-04 - val_mae: 0.0176\n",
            "Epoch 46/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3526e-04 - mae: 0.0108 - val_loss: 9.4939e-04 - val_mae: 0.0258\n",
            "Epoch 47/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1476e-04 - mae: 0.0102 - val_loss: 4.5132e-04 - val_mae: 0.0164\n",
            "Epoch 48/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 2.2564e-04 - mae: 0.0104 - val_loss: 6.8212e-04 - val_mae: 0.0211\n",
            "Epoch 49/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 2.0239e-04 - mae: 0.0098 - val_loss: 8.4120e-04 - val_mae: 0.0240\n",
            "Epoch 50/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.0880e-04 - mae: 0.0100 - val_loss: 7.7175e-04 - val_mae: 0.0227\n",
            "Epoch 1/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0419 - mae: 0.1454 - val_loss: 0.0028 - val_mae: 0.0421\n",
            "Epoch 2/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0024 - val_mae: 0.0365\n",
            "Epoch 3/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - mae: 0.0304 - val_loss: 0.0021 - val_mae: 0.0340\n",
            "Epoch 4/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0025 - val_mae: 0.0371\n",
            "Epoch 5/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0020 - val_mae: 0.0327\n",
            "Epoch 6/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0018 - val_mae: 0.0309\n",
            "Epoch 7/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0016 - val_mae: 0.0292\n",
            "Epoch 8/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0016 - val_mae: 0.0287\n",
            "Epoch 9/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0016 - val_mae: 0.0290\n",
            "Epoch 10/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0015 - val_mae: 0.0273\n",
            "Epoch 11/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0014 - val_mae: 0.0272\n",
            "Epoch 12/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.5890e-04 - mae: 0.0218 - val_loss: 0.0014 - val_mae: 0.0270\n",
            "Epoch 13/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.6615e-04 - mae: 0.0214 - val_loss: 0.0014 - val_mae: 0.0263\n",
            "Epoch 14/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.2473e-04 - mae: 0.0212 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 15/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.7093e-04 - mae: 0.0217 - val_loss: 0.0013 - val_mae: 0.0255\n",
            "Epoch 16/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 8.6632e-04 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 17/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 18/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 8.6860e-04 - mae: 0.0200 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 19/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 9.1586e-04 - mae: 0.0210 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 20/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 8.3032e-04 - mae: 0.0198 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 21/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.1917e-04 - mae: 0.0198 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 22/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.3834e-04 - mae: 0.0197 - val_loss: 0.0013 - val_mae: 0.0264\n",
            "Epoch 23/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 24/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 8.4900e-04 - mae: 0.0197 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 25/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.9482e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 26/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 8.0694e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mae: 0.0229\n",
            "Epoch 27/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.8034e-04 - mae: 0.0178 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 28/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 7.7846e-04 - mae: 0.0196 - val_loss: 0.0010 - val_mae: 0.0225\n",
            "Epoch 29/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 7.8230e-04 - mae: 0.0190 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 30/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.9560e-04 - mae: 0.0197 - val_loss: 9.9220e-04 - val_mae: 0.0222\n",
            "Epoch 31/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.1523e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0244\n",
            "Epoch 32/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.5663e-04 - mae: 0.0210 - val_loss: 0.0010 - val_mae: 0.0228\n",
            "Epoch 33/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.5980e-04 - mae: 0.0179 - val_loss: 0.0012 - val_mae: 0.0263\n",
            "Epoch 34/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 8.1310e-04 - mae: 0.0198 - val_loss: 9.6987e-04 - val_mae: 0.0220\n",
            "Epoch 35/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.2010e-04 - mae: 0.0180 - val_loss: 9.6145e-04 - val_mae: 0.0221\n",
            "Epoch 36/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.4486e-04 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0263\n",
            "Epoch 37/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.2885e-04 - mae: 0.0190 - val_loss: 0.0010 - val_mae: 0.0227\n",
            "Epoch 38/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.1958e-04 - mae: 0.0182 - val_loss: 9.5752e-04 - val_mae: 0.0220\n",
            "Epoch 39/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 6.8757e-04 - mae: 0.0186 - val_loss: 9.8640e-04 - val_mae: 0.0226\n",
            "Epoch 40/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 7.0562e-04 - mae: 0.0183 - val_loss: 9.3368e-04 - val_mae: 0.0216\n",
            "Epoch 41/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.6473e-04 - mae: 0.0172 - val_loss: 9.5405e-04 - val_mae: 0.0221\n",
            "Epoch 42/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.5876e-04 - mae: 0.0178 - val_loss: 9.1113e-04 - val_mae: 0.0213\n",
            "Epoch 43/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.1679e-04 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 44/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 6.3532e-04 - mae: 0.0178 - val_loss: 9.0460e-04 - val_mae: 0.0214\n",
            "Epoch 45/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.4180e-04 - mae: 0.0172 - val_loss: 9.1132e-04 - val_mae: 0.0214\n",
            "Epoch 46/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 6.1210e-04 - mae: 0.0171 - val_loss: 9.1406e-04 - val_mae: 0.0214\n",
            "Epoch 47/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.6415e-04 - mae: 0.0178 - val_loss: 8.9925e-04 - val_mae: 0.0212\n",
            "Epoch 48/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 5.6649e-04 - mae: 0.0164 - val_loss: 8.8644e-04 - val_mae: 0.0210\n",
            "Epoch 49/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 5.3494e-04 - mae: 0.0158 - val_loss: 8.8118e-04 - val_mae: 0.0211\n",
            "Epoch 50/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.7219e-04 - mae: 0.0162 - val_loss: 0.0020 - val_mae: 0.0357\n",
            "Epoch 1/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0124 - mae: 0.0802 - val_loss: 0.0021 - val_mae: 0.0322\n",
            "Epoch 2/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.1275e-04 - mae: 0.0192 - val_loss: 0.0014 - val_mae: 0.0255\n",
            "Epoch 3/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 4.9737e-04 - mae: 0.0153 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 4/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3430e-04 - mae: 0.0151 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 5/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 5.3583e-04 - mae: 0.0149 - val_loss: 9.5434e-04 - val_mae: 0.0204\n",
            "Epoch 6/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.0050e-04 - mae: 0.0134 - val_loss: 9.8258e-04 - val_mae: 0.0215\n",
            "Epoch 7/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.5364e-04 - mae: 0.0142 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 8/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.0998e-04 - mae: 0.0129 - val_loss: 8.2150e-04 - val_mae: 0.0190\n",
            "Epoch 9/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.7562e-04 - mae: 0.0128 - val_loss: 7.6930e-04 - val_mae: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.3576e-04 - mae: 0.0146 - val_loss: 8.2485e-04 - val_mae: 0.0196\n",
            "Epoch 11/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.5895e-04 - mae: 0.0123 - val_loss: 7.6172e-04 - val_mae: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.7633e-04 - mae: 0.0124 - val_loss: 7.2278e-04 - val_mae: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.1639e-04 - mae: 0.0116 - val_loss: 9.2482e-04 - val_mae: 0.0213\n",
            "Epoch 14/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.1918e-04 - mae: 0.0121 - val_loss: 9.1380e-04 - val_mae: 0.0213\n",
            "Epoch 15/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9450e-04 - mae: 0.0114 - val_loss: 9.6344e-04 - val_mae: 0.0217\n",
            "Epoch 16/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.1840e-04 - mae: 0.0117 - val_loss: 8.5315e-04 - val_mae: 0.0196\n",
            "Epoch 17/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0899e-04 - mae: 0.0114 - val_loss: 7.2539e-04 - val_mae: 0.0175\n",
            "Epoch 18/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.3423e-04 - mae: 0.0118 - val_loss: 7.7023e-04 - val_mae: 0.0179\n",
            "Epoch 19/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 3.4390e-04 - mae: 0.0120 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 20/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 3.1240e-04 - mae: 0.0118 - val_loss: 9.5531e-04 - val_mae: 0.0209\n",
            "Epoch 21/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.1570e-04 - mae: 0.0117 - val_loss: 6.5292e-04 - val_mae: 0.0167\n",
            "Epoch 22/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 3.0180e-04 - mae: 0.0114 - val_loss: 9.6189e-04 - val_mae: 0.0209\n",
            "Epoch 23/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 3.0856e-04 - mae: 0.0114 - val_loss: 9.4951e-04 - val_mae: 0.0205\n",
            "Epoch 24/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5925e-04 - mae: 0.0106 - val_loss: 0.0016 - val_mae: 0.0291\n",
            "Epoch 25/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.6258e-04 - mae: 0.0112 - val_loss: 7.7349e-04 - val_mae: 0.0176\n",
            "Epoch 26/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5630e-04 - mae: 0.0107 - val_loss: 9.4590e-04 - val_mae: 0.0204\n",
            "Epoch 27/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.8291e-04 - mae: 0.0109 - val_loss: 7.7450e-04 - val_mae: 0.0173\n",
            "Epoch 28/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.2389e-04 - mae: 0.0104 - val_loss: 8.6401e-04 - val_mae: 0.0185\n",
            "Epoch 29/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5632e-04 - mae: 0.0107 - val_loss: 0.0016 - val_mae: 0.0285\n",
            "Epoch 30/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.5098e-04 - mae: 0.0098 - val_loss: 8.0207e-04 - val_mae: 0.0177\n",
            "Epoch 31/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.3504e-04 - mae: 0.0100 - val_loss: 8.9571e-04 - val_mae: 0.0187\n",
            "Epoch 32/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.1998e-04 - mae: 0.0098 - val_loss: 0.0014 - val_mae: 0.0251\n",
            "Epoch 33/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5079e-04 - mae: 0.0107 - val_loss: 7.2215e-04 - val_mae: 0.0164\n",
            "Epoch 34/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4735e-04 - mae: 0.0105 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 35/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.5660e-04 - mae: 0.0107 - val_loss: 7.2454e-04 - val_mae: 0.0163\n",
            "Epoch 36/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 2.4619e-04 - mae: 0.0110 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 37/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4052e-04 - mae: 0.0104 - val_loss: 8.1710e-04 - val_mae: 0.0179\n",
            "Epoch 38/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.3655e-04 - mae: 0.0097 - val_loss: 0.0011 - val_mae: 0.0215\n",
            "Epoch 39/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0971e-04 - mae: 0.0095 - val_loss: 8.5640e-04 - val_mae: 0.0183\n",
            "Epoch 40/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1275e-04 - mae: 0.0094 - val_loss: 7.2045e-04 - val_mae: 0.0168\n",
            "Epoch 41/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 2.0396e-04 - mae: 0.0095 - val_loss: 0.0016 - val_mae: 0.0275\n",
            "Epoch 42/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 2.2261e-04 - mae: 0.0097 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 43/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2859e-04 - mae: 0.0105 - val_loss: 6.7653e-04 - val_mae: 0.0156\n",
            "Epoch 44/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.8766e-04 - mae: 0.0090 - val_loss: 9.7925e-04 - val_mae: 0.0200\n",
            "Epoch 45/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1703e-04 - mae: 0.0099 - val_loss: 8.2584e-04 - val_mae: 0.0176\n",
            "Epoch 46/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.4212e-04 - mae: 0.0103 - val_loss: 6.5597e-04 - val_mae: 0.0156\n",
            "Epoch 47/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 2.1409e-04 - mae: 0.0093 - val_loss: 6.6692e-04 - val_mae: 0.0156\n",
            "Epoch 48/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.1287e-04 - mae: 0.0096 - val_loss: 8.6645e-04 - val_mae: 0.0188\n",
            "Epoch 49/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0709e-04 - mae: 0.0093 - val_loss: 6.8554e-04 - val_mae: 0.0159\n",
            "Epoch 50/50\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1.8576e-04 - mae: 0.0090 - val_loss: 6.0222e-04 - val_mae: 0.0158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base paths on your laptop\n",
        "base_path = \"C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System\"\n",
        "processed_data_path = os.path.join(base_path, \"data/processed\")\n",
        "models_path = os.path.join(base_path, \"models/lstm\")\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(processed_data_path, exist_ok=True)\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "\n",
        "# Save processed sequence data and scalers per ticker\n",
        "for ticker, data in sequence_data.items():\n",
        "    # --- Save sequences (X_train, y_train, X_val, y_val) ---\n",
        "    seq_file = os.path.join(processed_data_path, f\"sequence_data_{ticker}.npz\")\n",
        "    np.savez(seq_file,\n",
        "             X_train=data['X_train'],\n",
        "             y_train=data['y_train'],\n",
        "             X_val=data['X_val'],\n",
        "             y_val=data['y_val'])\n",
        "    print(f\"Saved sequences for {ticker} → {seq_file}\")\n",
        "\n",
        "    # --- Save scaler ---\n",
        "    scaler_file = os.path.join(processed_data_path, f\"scaler_{ticker}.pkl\")\n",
        "    joblib.dump(data['scaler'], scaler_file)\n",
        "    print(f\"Saved scaler for {ticker} → {scaler_file}\")\n",
        "\n",
        "    # --- Save trained LSTM model ---\n",
        "    model_file = os.path.join(models_path, f\"lstm_model_{ticker}.h5\")\n",
        "    data['model'].save(model_file)\n",
        "    print(f\"Saved LSTM model for {ticker} → {model_file}\")\n",
        "\n",
        "print(\"\\nAll models and processed data saved locally!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow4vZqGVnb0N",
        "outputId": "4d09a514-71fc-47a7-f9e6-4e3f1d2a34e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sequences for AAPL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_AAPL.npz\n",
            "Saved scaler for AAPL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_AAPL.pkl\n",
            "Saved LSTM model for AAPL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_AAPL.h5\n",
            "Saved sequences for MSFT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_MSFT.npz\n",
            "Saved scaler for MSFT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_MSFT.pkl\n",
            "Saved LSTM model for MSFT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_MSFT.h5\n",
            "Saved sequences for GOOGL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_GOOGL.npz\n",
            "Saved scaler for GOOGL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_GOOGL.pkl\n",
            "Saved LSTM model for GOOGL → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_GOOGL.h5\n",
            "Saved sequences for AMZN → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_AMZN.npz\n",
            "Saved scaler for AMZN → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_AMZN.pkl\n",
            "Saved LSTM model for AMZN → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_AMZN.h5\n",
            "Saved sequences for TSLA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_TSLA.npz\n",
            "Saved scaler for TSLA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_TSLA.pkl\n",
            "Saved LSTM model for TSLA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_TSLA.h5\n",
            "Saved sequences for META → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_META.npz\n",
            "Saved scaler for META → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_META.pkl\n",
            "Saved LSTM model for META → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_META.h5\n",
            "Saved sequences for NVDA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_NVDA.npz\n",
            "Saved scaler for NVDA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_NVDA.pkl\n",
            "Saved LSTM model for NVDA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_NVDA.h5\n",
            "Saved sequences for JPM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_JPM.npz\n",
            "Saved scaler for JPM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_JPM.pkl\n",
            "Saved LSTM model for JPM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_JPM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sequences for V → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_V.npz\n",
            "Saved scaler for V → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_V.pkl\n",
            "Saved LSTM model for V → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_V.h5\n",
            "Saved sequences for JNJ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_JNJ.npz\n",
            "Saved scaler for JNJ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_JNJ.pkl\n",
            "Saved LSTM model for JNJ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_JNJ.h5\n",
            "Saved sequences for SPY → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_SPY.npz\n",
            "Saved scaler for SPY → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_SPY.pkl\n",
            "Saved LSTM model for SPY → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_SPY.h5\n",
            "Saved sequences for QQQ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_QQQ.npz\n",
            "Saved scaler for QQQ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_QQQ.pkl\n",
            "Saved LSTM model for QQQ → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_QQQ.h5\n",
            "Saved sequences for VTI → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_VTI.npz\n",
            "Saved scaler for VTI → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_VTI.pkl\n",
            "Saved LSTM model for VTI → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_VTI.h5\n",
            "Saved sequences for VOO → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_VOO.npz\n",
            "Saved scaler for VOO → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_VOO.pkl\n",
            "Saved LSTM model for VOO → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_VOO.h5\n",
            "Saved sequences for IWM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_IWM.npz\n",
            "Saved scaler for IWM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_IWM.pkl\n",
            "Saved LSTM model for IWM → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_IWM.h5\n",
            "Saved sequences for DIA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_DIA.npz\n",
            "Saved scaler for DIA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_DIA.pkl\n",
            "Saved LSTM model for DIA → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_DIA.h5\n",
            "Saved sequences for GLD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_GLD.npz\n",
            "Saved scaler for GLD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_GLD.pkl\n",
            "Saved LSTM model for GLD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_GLD.h5\n",
            "Saved sequences for TLT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_TLT.npz\n",
            "Saved scaler for TLT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_TLT.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved LSTM model for TLT → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_TLT.h5\n",
            "Saved sequences for BTC-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_BTC-USD.npz\n",
            "Saved scaler for BTC-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_BTC-USD.pkl\n",
            "Saved LSTM model for BTC-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_BTC-USD.h5\n",
            "Saved sequences for ETH-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_ETH-USD.npz\n",
            "Saved scaler for ETH-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_ETH-USD.pkl\n",
            "Saved LSTM model for ETH-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_ETH-USD.h5\n",
            "Saved sequences for BNB-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/sequence_data_BNB-USD.npz\n",
            "Saved scaler for BNB-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/processed/scaler_BNB-USD.pkl\n",
            "Saved LSTM model for BNB-USD → C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/models/lstm/lstm_model_BNB-USD.h5\n",
            "\n",
            "All models and processed data saved locally!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r saved_models_data.zip /content/data/processed /content/models/lstm\n",
        "from google.colab import files\n",
        "files.download(\"saved_models_data.zip\")\n"
      ],
      "metadata": {
        "id": "AihOHepf87YA",
        "outputId": "d842e926-27b5-4d64-fb63-7f42321485aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/data/processed/ (stored 0%)\n",
            "  adding: content/data/processed/scaler_AAPL.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_VOO.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_V.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_NVDA.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_QQQ.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_MSFT.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_META.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_TLT.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_VTI.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_SPY.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_BTC-USD.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_ETH-USD.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_GOOGL.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_AMZN.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_DIA.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_GLD.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_JNJ.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_BNB-USD.pkl (deflated 33%)\n",
            "  adding: content/data/processed/scaler_JPM.pkl (deflated 31%)\n",
            "  adding: content/data/processed/scaler_IWM.pkl (deflated 32%)\n",
            "  adding: content/data/processed/scaler_TSLA.pkl (deflated 33%)\n",
            "  adding: content/models/lstm/ (stored 0%)\n",
            "  adding: content/models/lstm/lstm_model_VTI.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_VOO.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_TLT.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_GLD.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_AAPL.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_NVDA.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_JPM.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_META.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_BTC-USD.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_MSFT.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_IWM.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_TSLA.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_BNB-USD.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_V.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_AMZN.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_ETH-USD.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_SPY.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_JNJ.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_QQQ.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_DIA.h5 (deflated 17%)\n",
            "  adding: content/models/lstm/lstm_model_GOOGL.h5 (deflated 17%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_feb4b9c7-9912-4112-88ea-91b61244b44e\", \"saved_models_data.zip\", 2740997)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "P-kDU6EKGr11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-forecasting pytorch-lightning\n"
      ],
      "metadata": {
        "id": "hCHGiN-0FxDO",
        "outputId": "9ac66557-4841-4f69-8800-9b453499f3b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-forecasting) (2.0.2)\n",
            "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-forecasting) (2.8.0+cu126)\n",
            "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
            "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.12/dist-packages (from pytorch-forecasting) (1.16.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-forecasting) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.12/dist-packages (from pytorch-forecasting) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
            "Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (4.15.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.11)\n",
            "Downloading pytorch_forecasting-1.5.0-py3-none-any.whl (391 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning, pytorch-forecasting\n",
            "Successfully installed lightning-2.5.6 lightning-utilities-0.15.2 pytorch-forecasting-1.5.0 pytorch-lightning-2.5.6 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Paths ---\n",
        "base_path = \"C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System\"\n",
        "processed_data_path = os.path.join(base_path, \"data/processed\")\n",
        "models_path = os.path.join(base_path, \"models/lstm\")\n",
        "raw_data_path = os.path.join(base_path, \"data/raw\")  # CSVs stored here\n",
        "\n",
        "# --- Parameters ---\n",
        "sequence_length = 60  # same as during training\n",
        "features = ['High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock_Splits', 'Capital_Gains']\n",
        "\n",
        "tickers = ['AAPL','MSFT','GOOGL','AMZN','TSLA','META','NVDA','JPM','SPY','QQQ','VTI','VOO','IWM','DIA','GLD','TLT','BTC-USD','ETH-USD','BNB-USD']  # add more if needed\n",
        "\n",
        "# --- Sliding window sequence creation ---\n",
        "def create_sequences(data, seq_len=60):\n",
        "    X, y = [], []\n",
        "    for i in range(seq_len, len(data)):\n",
        "        X.append(data[i-seq_len:i])\n",
        "        y.append(data[i, 2])  # 'Close' column index in features\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# --- Evaluation loop ---\n",
        "results = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        # Load raw CSV\n",
        "        csv_file = os.path.join(raw_data_path, f\"{ticker}.csv\")\n",
        "        df = pd.read_csv(csv_file)\n",
        "        df = df.sort_values('Date')  # ensure chronological order\n",
        "\n",
        "        # Select features\n",
        "        df_features = df[features].values\n",
        "\n",
        "        # Load scaler and apply\n",
        "        scaler_file = os.path.join(processed_data_path, f\"scaler_{ticker}.pkl\")\n",
        "        scaler = joblib.load(scaler_file)\n",
        "        scaled_data = scaler.transform(df_features)\n",
        "\n",
        "        # Create sequences\n",
        "        X, y = create_sequences(scaled_data, sequence_length)\n",
        "\n",
        "        # Train/val split (same as before)\n",
        "        train_size = int(len(X) * 0.8)\n",
        "        X_val, y_val = X[train_size:], y[train_size:]\n",
        "\n",
        "        # Load trained model\n",
        "        model_file = os.path.join(models_path, f\"lstm_model_{ticker}.h5\")\n",
        "        model = load_model(model_file)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_val)\n",
        "\n",
        "        # Inverse scale for 'Close' column\n",
        "        close_index = features.index('Close')\n",
        "        y_val_scaled = np.zeros((len(y_val), len(features)))\n",
        "        y_val_scaled[:, close_index] = y_val\n",
        "        y_val_actual = scaler.inverse_transform(y_val_scaled)[:, close_index]\n",
        "\n",
        "        y_pred_scaled = np.zeros((len(y_pred), len(features)))\n",
        "        y_pred_scaled[:, close_index] = y_pred.flatten()\n",
        "        y_pred_actual = scaler.inverse_transform(y_pred_scaled)[:, close_index]\n",
        "\n",
        "        # Metrics\n",
        "        rmse = np.sqrt(mean_squared_error(y_val_actual, y_pred_actual))\n",
        "        mae = mean_absolute_error(y_val_actual, y_pred_actual)\n",
        "        mape = np.mean(np.abs((y_val_actual - y_pred_actual)/y_val_actual)) * 100\n",
        "\n",
        "        results[ticker] = {'RMSE': rmse, 'MAE': mae, 'MAPE': mape}\n",
        "\n",
        "        # Plot predicted vs actual\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(y_val_actual, label='Actual')\n",
        "        plt.plot(y_pred_actual, label='Predicted')\n",
        "        plt.title(f\"{ticker} - Predicted vs Actual\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Close Price\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"✅ {ticker} - RMSE: {rmse:.2f}, MAE: {mae:.2f}, MAPE: {mape:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[❌] Error with {ticker}: {e}\")\n",
        "\n",
        "# --- Summary table ---\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(\"\\nAll tickers evaluation metrics:\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "lM4bLecXGoVF",
        "outputId": "d98d0597-58c2-469c-8106-7e1ff4d5c14c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[❌] Error with AAPL: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/AAPL.csv'\n",
            "[❌] Error with MSFT: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/MSFT.csv'\n",
            "[❌] Error with GOOGL: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/GOOGL.csv'\n",
            "[❌] Error with AMZN: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/AMZN.csv'\n",
            "[❌] Error with TSLA: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/TSLA.csv'\n",
            "[❌] Error with META: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/META.csv'\n",
            "[❌] Error with NVDA: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/NVDA.csv'\n",
            "[❌] Error with JPM: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/JPM.csv'\n",
            "[❌] Error with SPY: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/SPY.csv'\n",
            "[❌] Error with QQQ: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/QQQ.csv'\n",
            "[❌] Error with VTI: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/VTI.csv'\n",
            "[❌] Error with VOO: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/VOO.csv'\n",
            "[❌] Error with IWM: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/IWM.csv'\n",
            "[❌] Error with DIA: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/DIA.csv'\n",
            "[❌] Error with GLD: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/GLD.csv'\n",
            "[❌] Error with TLT: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/TLT.csv'\n",
            "[❌] Error with BTC-USD: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/BTC-USD.csv'\n",
            "[❌] Error with ETH-USD: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/ETH-USD.csv'\n",
            "[❌] Error with BNB-USD: [Errno 2] No such file or directory: 'C:/Users/Swara/Desktop/Projects/Personalized Investment Recommendation System/Personalized-Investment-Recommendation-System/data/raw/BNB-USD.csv'\n",
            "\n",
            "All tickers evaluation metrics:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UngoF-QYGzK8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}